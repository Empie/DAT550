{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import log\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_df(df):\n",
    "    for col in df.columns:\n",
    "        if df[col].unique().dtype == \"int64\" or df[col].unique().dtype == \"float64\":\n",
    "            df[col] = df[col].fillna(df[col].median())\n",
    "            if df[col].unique().dtype == \"float64\":\n",
    "                df[col] = df[col].astype('int64')\n",
    "        else:\n",
    "            df[col] = df[col].fillna(\"NA\")\n",
    "            df[col] = df[col].astype('category')\n",
    "            \n",
    "    # Hardcoding numeric to categorical\n",
    "    df[\"MSSubClass\"] = df[\"MSSubClass\"].astype('category')\n",
    "    df[\"OverallQual\"] = df[\"OverallQual\"].astype('category')\n",
    "    df[\"OverallCond\"] = df[\"OverallCond\"].astype('category')\n",
    "    return df\n",
    "    \n",
    "def df_to_numerical(df):\n",
    "    numerical_df = pd.DataFrame()\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == \"int64\":\n",
    "            numerical_df[col] = df[col]\n",
    "            continue\n",
    "        else:\n",
    "            df[col] = df[col].astype(\"category\")\n",
    "            new_col = '{val}_Cat'.format(val=col)\n",
    "            numerical_df[new_col] = df[col].cat.codes\n",
    "    return numerical_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest():\n",
    "    def __init__(self):\n",
    "        self.data = None  # training data set (loaded into memory)\n",
    "        self.trees = []  # decision trees\n",
    "    \n",
    "    def __load_data(self, df):\n",
    "        self.data = df\n",
    "        \n",
    "    def __subsampling(self, train_set, sample_size_ratio):\n",
    "        sample_number = round(len(self.data) * sample_size_ratio)\n",
    "        subsample = train_set.sample(sample_number, replace=True)\n",
    "        return subsample\n",
    "\n",
    "    def build_model(self, train_set, sample_size_ratio, number_of_trees):\n",
    "        self.__load_data(train_set)\n",
    "        for i in range(number_of_trees):\n",
    "            sample = self.__subsampling(train_set, sample_size_ratio)\n",
    "            X = sample.iloc[:,:-1]\n",
    "            y = sample.iloc[:,-1]\n",
    "            tree = DecisionTree(max_depth=3) # build a tree with sample data and split conditions\n",
    "            tree.fit(X, y)\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    def predict(self, test_set):\n",
    "        rf_predictions = []\n",
    "        rf_predictions_mean = []\n",
    "        for tree in self.trees:\n",
    "            rf_predictions.append(tree.predict(test_set))\n",
    "        for i in range(len(rf_predictions)):\n",
    "            rf_predictions_mean.append(np.mean(rf_predictions[i]))\n",
    "        return rf_predictions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionNode():\n",
    "    def __init__(self, feature_idx=None, threshold=None, value=None, true_branch=None, false_branch=None):\n",
    "        self.feature_idx = feature_idx # index of the feature that is used\n",
    "        self.threshold = threshold # threshold value for feature when making the decision\n",
    "        self.value = value # value if the node is a leaf in the tree\n",
    "        self.true_branch = true_branch # the node we go to if decision returns True\n",
    "        self.false_branch = false_branch # the node we go to if decision returns False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree():\n",
    "    def __init__(self, min_info_gain=1e-7, max_depth=float(\"inf\")):\n",
    "        self.root = None # root of this tree\n",
    "        self.min_info_gain = min_info_gain # minimum information gain to allow splitting\n",
    "        self.max_depth = max_depth # maximum depth the tree grows to\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.root = self.build_tree(X, y)\n",
    "        \n",
    "    def build_tree(self, X, y, current_depth=0):\n",
    "        decision = None\n",
    "        subtrees = None\n",
    "        largest_info_gain = 0\n",
    "        max_variance_reduction = -float('inf')\n",
    "        df = pd.concat((X, y), axis=1)\n",
    "        n_rows, n_features = X.shape\n",
    "        if current_depth <= self.max_depth:\n",
    "            for feature_idx in range(n_features):\n",
    "                feature_values = X.iloc[:, feature_idx]\n",
    "                unique_values = feature_values.unique()\n",
    "                for threshold in unique_values:\n",
    "                    X_true, X_false = self.split_by_feature(df, feature_idx, threshold)\n",
    "                    if len(X_true) > 0 and len(X_false) > 0:\n",
    "                        y_true = X_true.iloc[:,-1]\n",
    "                        y_false = X_false.iloc[:,-1]\n",
    "                        #info_gain = self.calculate_information_gain(y, y_true, y_false)\n",
    "                        variance_reduction = self.reduce_variance(y,y_true,y_false)\n",
    "                        #print(variance_reduction)\n",
    "                        if variance_reduction > max_variance_reduction:\n",
    "                            max_variance_reduction = variance_reduction\n",
    "                            #largest_info_gain = info_gain\n",
    "                            decision = {\"feature_idx\":feature_idx, \"threshold\":threshold}\n",
    "                            subtrees = {\"X_true\":X_true.iloc[:,:-1],\n",
    "                                        \"y_true\":y_true,\n",
    "                                        \"X_false\":X_false.iloc[:,:-1],\n",
    "                                        \"y_false\":y_false}\n",
    "        # we will construct new branch if the information gain is larger than minimum information gain that we've defined\n",
    "        if max_variance_reduction < self.min_info_gain:\n",
    "            true_branch = self.build_tree(subtrees[\"X_true\"], subtrees[\"y_true\"], current_depth+1)\n",
    "            false_branch = self.build_tree(subtrees[\"X_false\"], subtrees[\"y_false\"], current_depth+1)\n",
    "            return DecisionNode(feature_idx=decision[\"feature_idx\"], threshold=decision[\"threshold\"], true_branch=true_branch, false_branch=false_branch)\n",
    "\n",
    "        return DecisionNode(value=np.mean(y))\n",
    "\n",
    "    def split_by_feature(self, X, feature_idx, threshold):\n",
    "        # if the feature is numerical\n",
    "        if X.iloc[:,feature_idx].dtype == \"int64\":\n",
    "            X_true = X[X.iloc[:,feature_idx] >= threshold]\n",
    "            X_false = X[X.iloc[:,feature_idx] < threshold]\n",
    "        # if the feature is categorical\n",
    "        else:\n",
    "            X_true = X[X.iloc[:,feature_idx] == threshold]\n",
    "            X_false = X[X.iloc[:,feature_idx] != threshold]\n",
    "        return X_true, X_false\n",
    "\n",
    "    def reduce_variance(self, y, y_true, y_false):\n",
    "        p_true = len(y_true)/len(y)\n",
    "        p_false = len(y_false)/len(y)\n",
    "        return np.var(y)-(p_true*np.var(y_true))-(p_false*np.var(y_false))\n",
    "\n",
    "                \n",
    "    def predict_value(self, x, tree=None):\n",
    "        # recursive method to find the leaf node that corresponds to prediction\n",
    "        if tree is None:\n",
    "            tree = self.root\n",
    "        if tree.value is not None:\n",
    "            return tree.value\n",
    "        feature_value = x[tree.feature_idx]\n",
    "        branch = tree.false_branch\n",
    "        if isinstance(feature_value, int) or isinstance(feature_value, float):\n",
    "            if feature_value >= tree.threshold:\n",
    "                branch = tree.true_branch\n",
    "        elif feature_value == tree.threshold:\n",
    "            branch = tree.true_branch\n",
    "        return self.predict_value(x, branch)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        y_pred = []\n",
    "        for x in X:\n",
    "            y_pred.append(self.predict_value(x, self.root))\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('housing_price_train.csv')\n",
    "df = preprocess_df(df)\n",
    "X_test = pd.read_csv('housing_price_test.csv')\n",
    "X_test = preprocess_df(X_test)\n",
    "\n",
    "X_train = df.iloc[:,:-1]\n",
    "y_train = df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_to_numerical(X_train)\n",
    "# X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForest()\n",
    "rf.build_model(train_set = X_train, sample_size_ratio=0.3, number_of_trees=2)\n",
    "rf.predict(X_test)\n",
    "pd.Series(rf.predict(X_test)).to_csv('samples.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree = DecisionTree(max_depth=3)\n",
    "# tree.fit(X_train, y_train)\n",
    "# tree.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
