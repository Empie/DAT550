{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1d) Check whether a tweet is attention-worthy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\minh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "import spacy\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\") # Ignore warnings\n",
    "nltk.download('stopwords') # Load Stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\") # Load Lemmatizer\n",
    "cachedStopWords = list(set(stopwords.words(\"english\")))\n",
    "\n",
    "# Twitter Datasets\n",
    "df_worthy_train = pd.read_csv(\"data/1d/CT22_english_1D_attentionworthy_train.tsv\", sep='\\t')\n",
    "df_worthy_valid = pd.read_csv(\"data/1d/CT22_english_1D_attentionworthy_dev.tsv\", sep='\\t')\n",
    "df_worthy_test = pd.read_csv(\"data/1d/CT22_english_1D_attentionworthy_dev_test.tsv\", sep='\\t')\n",
    "\n",
    "# Top 3000 most commonly used english words + covid related medical terms (used as vocabulary for the vectorization process)\n",
    "topwords = pd.read_csv('words.txt', sep=\" \", header=None).values[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test shape: (909, 5)\n",
      "Train shape: (3321, 5)\n",
      "Validation shape: (306, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_url</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>class_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COVID-19</td>\n",
       "      <td>1.359351e+18</td>\n",
       "      <td>http://twitter.com/user/status/135935094335617...</td>\n",
       "      <td>India's gift of 100,000 COVID-19 vaccines arri...</td>\n",
       "      <td>no_not_interesting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COVID-19</td>\n",
       "      <td>1.350166e+18</td>\n",
       "      <td>http://twitter.com/user/status/135016568806166...</td>\n",
       "      <td>Here’s what I’m doing while I wait my turn for...</td>\n",
       "      <td>no_not_interesting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>COVID-19</td>\n",
       "      <td>1.369750e+18</td>\n",
       "      <td>http://twitter.com/user/status/136974953915491...</td>\n",
       "      <td>This afternoon, I’m hosting an event with the ...</td>\n",
       "      <td>no_not_interesting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>COVID-19</td>\n",
       "      <td>1.350165e+18</td>\n",
       "      <td>http://twitter.com/user/status/135016499568693...</td>\n",
       "      <td>Help shops like mine stay open. Mask up, avoid...</td>\n",
       "      <td>no_not_interesting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>COVID-19</td>\n",
       "      <td>1.370008e+18</td>\n",
       "      <td>http://twitter.com/user/status/137000807648978...</td>\n",
       "      <td>As part of the ongoing nationwide vaccination ...</td>\n",
       "      <td>no_not_interesting</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      topic      tweet_id                                          tweet_url  \\\n",
       "0  COVID-19  1.359351e+18  http://twitter.com/user/status/135935094335617...   \n",
       "1  COVID-19  1.350166e+18  http://twitter.com/user/status/135016568806166...   \n",
       "2  COVID-19  1.369750e+18  http://twitter.com/user/status/136974953915491...   \n",
       "3  COVID-19  1.350165e+18  http://twitter.com/user/status/135016499568693...   \n",
       "4  COVID-19  1.370008e+18  http://twitter.com/user/status/137000807648978...   \n",
       "\n",
       "                                          tweet_text         class_label  \n",
       "0  India's gift of 100,000 COVID-19 vaccines arri...  no_not_interesting  \n",
       "1  Here’s what I’m doing while I wait my turn for...  no_not_interesting  \n",
       "2  This afternoon, I’m hosting an event with the ...  no_not_interesting  \n",
       "3  Help shops like mine stay open. Mask up, avoid...  no_not_interesting  \n",
       "4  As part of the ongoing nationwide vaccination ...  no_not_interesting  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Test shape: {}\\nTrain shape: {}\\nValidation shape: {}\".format(df_worthy_test.shape, df_worthy_train.shape, df_worthy_valid.shape))\n",
    "df_worthy_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling imbalanced multiclass text classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories: ['no_not_interesting' 'harmful' 'yes_calls_for_action'\n",
      " 'yes_blame_authorities' 'yes_discusses_cure' 'yes_discusses_action_taken'\n",
      " 'yes_asks_question' 'yes_contains_advice' 'yes_other']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Categories vs Number of Documents'}>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "categories = df_worthy_train.class_label.unique()\n",
    "print('Categories: {}'.format(categories))\n",
    "df_worthy_train.class_label.value_counts().plot(kind='bar', title='Categories vs Number of Documents', cmap='plasma')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no_not_interesting            2851\n",
       "harmful                        173\n",
       "yes_blame_authorities          138\n",
       "yes_calls_for_action            48\n",
       "yes_discusses_cure              42\n",
       "yes_discusses_action_taken      27\n",
       "yes_other                       25\n",
       "yes_contains_advice             12\n",
       "yes_asks_question                5\n",
       "Name: class_label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_worthy_train[\"class_label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dfs = {}\n",
    "\n",
    "for label in df_worthy_train[\"class_label\"].unique():\n",
    "    label_dfs[label] = df_worthy_train[df_worthy_train[\"class_label\"] == label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no_not_interesting            5\n",
       "harmful                       5\n",
       "yes_calls_for_action          5\n",
       "yes_blame_authorities         5\n",
       "yes_discusses_cure            5\n",
       "yes_discusses_action_taken    5\n",
       "yes_asks_question             5\n",
       "yes_contains_advice           5\n",
       "yes_other                     5\n",
       "Name: class_label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "downsampled_dfs = {}\n",
    "minority_class = min(df_worthy_train[\"class_label\"].value_counts())\n",
    "\n",
    "for key, val in label_dfs.items():\n",
    "    downsampled_dfs[\"downsampled_\" + key] = val.sample(n=minority_class)\n",
    "\n",
    "df_downsampled = pd.concat(downsampled_dfs.values())\n",
    "df_downsampled[\"class_label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no_not_interesting            2851\n",
       "harmful                       2851\n",
       "yes_calls_for_action          2851\n",
       "yes_blame_authorities         2851\n",
       "yes_discusses_cure            2851\n",
       "yes_discusses_action_taken    2851\n",
       "yes_asks_question             2851\n",
       "yes_contains_advice           2851\n",
       "yes_other                     2851\n",
       "Name: class_label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upsampled_dfs = {}\n",
    "majority_class = max(df_worthy_train[\"class_label\"].value_counts())\n",
    "\n",
    "for key, val in label_dfs.items():\n",
    "    upsampled_dfs[\"upsampled_\" + key] = val.sample(n=majority_class, replace=True)\n",
    "\n",
    "df_upsampled = pd.concat(upsampled_dfs.values())\n",
    "df_upsampled[\"class_label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combination of over- and undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no_not_interesting            369\n",
       "harmful                       369\n",
       "yes_calls_for_action          369\n",
       "yes_blame_authorities         369\n",
       "yes_discusses_cure            369\n",
       "yes_discusses_action_taken    369\n",
       "yes_asks_question             369\n",
       "yes_contains_advice           369\n",
       "yes_other                     369\n",
       "Name: class_label, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meansampled_dfs = {}\n",
    "mean_val = df_worthy_train[\"class_label\"].value_counts().mean()\n",
    "\n",
    "for key, val in label_dfs.items():\n",
    "    meansampled_dfs[\"meansampled\" + key] = val.sample(n=int(mean_val), replace=True)\n",
    "\n",
    "df_meansampled = pd.concat(meansampled_dfs.values())\n",
    "df_meansampled[\"class_label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/how-to-handle-multiclass-imbalanced-data-say-no-to-smote-e9a7f393c310\n",
    "from sklearn.utils import class_weight\n",
    "class_weights = list(class_weight.compute_class_weight(class_weight= 'balanced', \n",
    "                                                       classes = np.unique(df_worthy_train[\"class_label\"]), \n",
    "                                                       y = df_worthy_train[\"class_label\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no_not_interesting            2851\n",
       "harmful                        173\n",
       "yes_blame_authorities          138\n",
       "yes_calls_for_action            48\n",
       "yes_discusses_cure              42\n",
       "yes_discusses_action_taken      27\n",
       "yes_other                       25\n",
       "yes_contains_advice             12\n",
       "yes_asks_question                5\n",
       "Name: class_label, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_worthy_train[\"class_label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df_worthy_train[\"class_label\"].value_counts().index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'no_not_interesting': 0.1294282707821817,\n",
       " 'harmful': 2.132947976878613,\n",
       " 'yes_blame_authorities': 2.6739130434782608,\n",
       " 'yes_calls_for_action': 7.6875,\n",
       " 'yes_discusses_cure': 8.785714285714286,\n",
       " 'yes_discusses_action_taken': 13.666666666666666,\n",
       " 'yes_other': 14.76,\n",
       " 'yes_contains_advice': 30.75,\n",
       " 'yes_asks_question': 73.8}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating weights\n",
    "class_weights.sort()\n",
    "class_weights\n",
    "\n",
    "df_worthy_train[\"class_label\"].value_counts()\n",
    "\n",
    "weights = {}\n",
    "for index, weight in enumerate(class_weights):\n",
    "    weights[labels[index]] = weight\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emoji Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove emojies when using the lemmatizer\n",
    "#https://poopcode.com/how-to-remove-emoji-from-text-in-python/\n",
    "def remove_emoji(string):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               u\"\\U0001f926-\\U0001f937\"\n",
    "                               u\"\\U00010000-\\U0010ffff\"\n",
    "                               u\"\\u2640-\\u2642\"\n",
    "                               u\"\\u2600-\\u2B55\"\n",
    "                               u\"\\u200d\"\n",
    "                               u\"\\u23cf\"\n",
    "                               u\"\\u23e9\"\n",
    "                               u\"\\u231a\"\n",
    "                               u\"\\ufe0f\"  # dingbats\n",
    "                               u\"\\u3030\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(text, method=\"stopwords\"):\n",
    "    \n",
    "    # Remove hyperlinks\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    \n",
    "    # Split sentence into words\n",
    "    tokens = []\n",
    "    for token in ngrams(text.split(), 1):\n",
    "        word = re.sub(r',', '', token[0]) #Remove commas\n",
    "        word = re.sub(r'[\\!\\.\\:]$', '', word) #Remove (.!:) at the end of tokens\n",
    "        word = re.sub(r'#', '', word) #Remove hashtags (not the text)\n",
    "        if word == \"—\": continue #Ignore dash\n",
    "        if word.find(\"@\") != -1: continue #Ignore tags\n",
    "        tokens.append(word)\n",
    "    tokens\n",
    "\n",
    "    # List comprehension to remove stopwords\n",
    "    if method != \"default\":\n",
    "        tokens = [x for x in tokens if x not in cachedStopWords]\n",
    "\n",
    "    # Perform stemming\n",
    "    if method == \"stemming\":\n",
    "        ps = PorterStemmer()\n",
    "        tokens = [ps.stem(x) for x in tokens]\n",
    "\n",
    "    # Perform lemmatization\n",
    "    if method == \"lemmatizer\":\n",
    "        # Remove emojies due to lemmatizer not handling them well\n",
    "        tokens = [x for x in tokens if remove_emoji(x) == x]\n",
    "        text = \" \".join(tokens)\n",
    "        doc = nlp(text)\n",
    "        tokens = [token.lemma_ for token in doc]\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_normal(text):\n",
    "    return tokenize_text(text, method=\"default\")\n",
    "\n",
    "def tokenize_stopwords(text):\n",
    "    return tokenize_text(text, method=\"stopwords\")\n",
    "\n",
    "def tokenize_stemming(text):\n",
    "    return tokenize_text(text, method=\"stemming\")\n",
    "\n",
    "def tokenize_lemmatizer(text):\n",
    "    return tokenize_text(text, method=\"lemmatizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_df(df, text_col, method=\"default\"):\n",
    "    article_tokens = []\n",
    "    for i in range(len(df)):\n",
    "        text = df.iloc[i][text_col].lower()\n",
    "        article_tokens.append(tokenize_text(text, method))\n",
    "    df[\"tokens\"] = article_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize_df(df_downsampled, \"tweet_text\", \"lemmatizer\")\n",
    "tokenize_df(df_upsampled, \"tweet_text\", \"lemmatizer\")\n",
    "tokenize_df(df_meansampled, \"tweet_text\", \"lemmatizer\")\n",
    "tokenize_df(df_worthy_train, \"tweet_text\", \"lemmatizer\")\n",
    "tokenize_df(df_worthy_test, \"tweet_text\", \"lemmatizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['break', 'pre', 'duterte', 'declare', 'walangpasok', 'level', 'metro', 'manila', 'march', '14', 'due', 'covid19', '|via', 'cnn', 'philippines'] \n",
      "\n",
      "['china', 'country', 'say', 'launch', 'new', 'programme', 'provide', 'million', 'covid-19', 'vaccine', 'national', 'africa', 'elsewhere', 'overseas', 'accord', 'foreign', 'minister', 'wang', 'yi'] \n",
      "\n",
      "['single', '-', 'dose', 'j&amp;j', 'covid-19', 'vaccine', 'administer', 'sat', 'march', '13', 'sun', 'march', '14', '9', 'a.m', '5', 'p.m', 'available', 'number', 'vaccine', 'run', 'anyone', 'already', 'receive', 'dose', 'either', 'moderna', 'pfizer', 'vaccine', 'visit', 'site'] \n",
      "\n",
      "['india', \"'s\", 'gift', '100000', 'covid-19', 'vaccine', 'arrive', 'barbado', 'early', 'today', 'special', 'moment', 'barbadian', 'want', 'thank', 'prime', 'minister', 'modi', 'quick', 'decisive', 'magnanimous', 'action', 'allow', 'we', 'beneficiary', 'vaccine'] \n",
      "\n",
      "['senate', 'pass', 'covid', 'relief', '$', '1400', 'relief', 'check', 'fund', 'vaccine', 'money', 'reopen', 'school', 'food', 'unemployment', 'rental', 'assistance', 'cut', 'child', 'poverty', 'half', 'help', 'small', 'business', 'must', 'end', 'pandemic', 'help', 'way']\n"
     ]
    }
   ],
   "source": [
    "print(df_downsampled.iloc[0][\"tokens\"], \"\\n\")\n",
    "print(df_upsampled.iloc[0][\"tokens\"], \"\\n\")\n",
    "print(df_meansampled.iloc[0][\"tokens\"], \"\\n\")\n",
    "print(df_worthy_train.iloc[0][\"tokens\"], \"\\n\")\n",
    "print(df_worthy_test.iloc[0][\"tokens\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer # For creating a DTM (discrete values)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # A weighted DTM (fractions)\n",
    "\n",
    "cv_dict = {}\n",
    "tfidf_dict = {}\n",
    "ngram_list = [1,2,3]\n",
    "for n in ngram_list:\n",
    "    cv_dict[n] = CountVectorizer(tokenizer=tokenize_lemmatizer, ngram_range=(n, n), max_features=5000)\n",
    "    tfidf_dict[n] = TfidfVectorizer(tokenizer=tokenize_stopwords, ngram_range=(n, n), max_features=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_vec = {}\n",
    "tweet_bow_train = {}\n",
    "tweet_bow_val = {}\n",
    "tweet_bow_test = {}\n",
    "\n",
    "tweet_vec_d = {}\n",
    "tweet_bow_train_d = {}\n",
    "tweet_bow_val_d = {}\n",
    "tweet_bow_test_d = {}\n",
    "\n",
    "tweet_vec_u = {}\n",
    "tweet_bow_train_u = {}\n",
    "tweet_bow_val_u = {}\n",
    "tweet_bow_test_u = {}\n",
    "\n",
    "tweet_vec_h = {}\n",
    "tweet_bow_train_h = {}\n",
    "tweet_bow_val_h = {}\n",
    "tweet_bow_test_h = {}\n",
    "for n in ngram_list:\n",
    "    #tweet_vec[n] = tfidf_dict[n].fit(df_worthy_train[\"tweet_text\"]) # DTM (CV, but normalized for relative frequency)\n",
    "    tweet_vec[n] = cv_dict[n].fit(df_worthy_train[\"tweet_text\"]) # DTM (CV, but normalized for relative frequency)\n",
    "    tweet_bow_train[n] = tweet_vec[n].transform(df_worthy_train[\"tweet_text\"]) \n",
    "    tweet_bow_test[n] = tweet_vec[n].transform(df_worthy_test[\"tweet_text\"]) \n",
    "    tweet_bow_val[n] = tweet_vec[n].transform(df_worthy_valid[\"tweet_text\"]) \n",
    "    \n",
    "    # balanced downsample\n",
    "    #tweet_vec_d[n] = tfidf_dict[n].fit(df_balanced_d[\"tweet_text\"])\n",
    "    tweet_vec_d[n] = cv_dict[n].fit(df_downsampled[\"tweet_text\"]) # DTM (CV, but normalized for relative frequency)\n",
    "    tweet_bow_train_d[n] = tweet_vec_d[n].transform(df_downsampled[\"tweet_text\"]) \n",
    "    tweet_bow_test_d[n] = tweet_vec_d[n].transform(df_worthy_test[\"tweet_text\"]) \n",
    "    tweet_bow_val_d[n] = tweet_vec_d[n].transform(df_worthy_valid[\"tweet_text\"]) \n",
    "    \n",
    "    # balanced upsample\n",
    "    #tweet_vec_u[n] = tfidf_dict[n].fit(df_balanced_u[\"tweet_text\"]) \n",
    "    tweet_vec_u[n] = cv_dict[n].fit(df_upsampled[\"tweet_text\"]) # DTM (CV, but normalized for relative frequency)\n",
    "    tweet_bow_train_u[n] = tweet_vec_u[n].transform(df_upsampled[\"tweet_text\"]) \n",
    "    tweet_bow_test_u[n] = tweet_vec_u[n].transform(df_worthy_test[\"tweet_text\"]) \n",
    "    tweet_bow_val_u[n] = tweet_vec_u[n].transform(df_worthy_valid[\"tweet_text\"])\n",
    "    \n",
    "    # balanced hybridsample\n",
    "    #tweet_vec_h[n] = tfidf_dict[n].fit(df_balanced_h[\"tweet_text\"])\n",
    "    tweet_vec_h[n] = cv_dict[n].fit(df_meansampled[\"tweet_text\"]) # DTM (CV, but normalized for relative frequency)\n",
    "    tweet_bow_train_h[n] = tweet_vec_h[n].transform(df_meansampled[\"tweet_text\"]) \n",
    "    tweet_bow_test_h[n] = tweet_vec_h[n].transform(df_worthy_test[\"tweet_text\"]) \n",
    "    tweet_bow_val_h[n] = tweet_vec_h[n].transform(df_worthy_valid[\"tweet_text\"]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Unbalanced--------\n",
      "1-gram Priors: [0.05209274 0.85847636 0.00150557 0.04155375 0.01445348 0.00361337\n",
      " 0.00813008 0.01264679 0.00752785]\n",
      "Dummy F1-Score for 1-gram: 91.98%\n",
      "Dummy Precision-Score for 1-gram: 11.11%\n",
      "Dummy Recall-Score for 1-gram: 9.46%\n",
      "--------Downsampled--------\n",
      "1-gram Priors: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "Dummy F1-Score for 1-gram: 11.41%\n",
      "Dummy Precision-Score for 1-gram: 11.11%\n",
      "Dummy Recall-Score for 1-gram: 0.67%\n",
      "--------Upsampled--------\n",
      "1-gram Priors: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "Dummy F1-Score for 1-gram: 11.41%\n",
      "Dummy Precision-Score for 1-gram: 11.11%\n",
      "Dummy Recall-Score for 1-gram: 0.67%\n",
      "--------Meansampled--------\n",
      "1-gram Priors: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "Dummy F1-Score for 1-gram: 11.41%\n",
      "Dummy Precision-Score for 1-gram: 11.11%\n",
      "Dummy Recall-Score for 1-gram: 0.67%\n",
      "--------------------------------------\n",
      "--------Unbalanced--------\n",
      "2-gram Priors: [0.05209274 0.85847636 0.00150557 0.04155375 0.01445348 0.00361337\n",
      " 0.00813008 0.01264679 0.00752785]\n",
      "Dummy F1-Score for 2-gram: 91.98%\n",
      "Dummy Precision-Score for 2-gram: 11.11%\n",
      "Dummy Recall-Score for 2-gram: 9.46%\n",
      "--------Downsampled--------\n",
      "2-gram Priors: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "Dummy F1-Score for 2-gram: 11.41%\n",
      "Dummy Precision-Score for 2-gram: 11.11%\n",
      "Dummy Recall-Score for 2-gram: 0.67%\n",
      "--------Upsampled--------\n",
      "2-gram Priors: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "Dummy F1-Score for 2-gram: 11.41%\n",
      "Dummy Precision-Score for 2-gram: 11.11%\n",
      "Dummy Recall-Score for 2-gram: 0.67%\n",
      "--------Meansampled--------\n",
      "2-gram Priors: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "Dummy F1-Score for 2-gram: 11.41%\n",
      "Dummy Precision-Score for 2-gram: 11.11%\n",
      "Dummy Recall-Score for 2-gram: 0.67%\n",
      "--------------------------------------\n",
      "--------Unbalanced--------\n",
      "3-gram Priors: [0.05209274 0.85847636 0.00150557 0.04155375 0.01445348 0.00361337\n",
      " 0.00813008 0.01264679 0.00752785]\n",
      "Dummy F1-Score for 3-gram: 91.98%\n",
      "Dummy Precision-Score for 3-gram: 11.11%\n",
      "Dummy Recall-Score for 3-gram: 9.46%\n",
      "--------Downsampled--------\n",
      "3-gram Priors: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "Dummy F1-Score for 3-gram: 11.41%\n",
      "Dummy Precision-Score for 3-gram: 11.11%\n",
      "Dummy Recall-Score for 3-gram: 0.67%\n",
      "--------Upsampled--------\n",
      "3-gram Priors: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "Dummy F1-Score for 3-gram: 11.41%\n",
      "Dummy Precision-Score for 3-gram: 11.11%\n",
      "Dummy Recall-Score for 3-gram: 0.67%\n",
      "--------Meansampled--------\n",
      "3-gram Priors: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "Dummy F1-Score for 3-gram: 11.41%\n",
      "Dummy Precision-Score for 3-gram: 11.11%\n",
      "Dummy Recall-Score for 3-gram: 0.67%\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "for n in ngram_list:\n",
    "    print(\"--------Unbalanced--------\")\n",
    "    dummy_clf = DummyClassifier(strategy=\"prior\")\n",
    "    dummy_clf.fit(tweet_bow_train[n], df_worthy_train[\"class_label\"])\n",
    "    print(\"{}-gram Priors: {}\".format(n, dummy_clf.class_prior_))\n",
    "\n",
    "    f1_score = metrics.f1_score(dummy_clf.predict(tweet_bow_test[n]), df_worthy_test[\"class_label\"], average=\"weighted\")\n",
    "    print(\"Dummy F1-Score for {}-gram: {}%\".format(n, round(f1_score * 100, 2)))\n",
    "    \n",
    "    precision_score = metrics.precision_score(dummy_clf.predict(tweet_bow_test[n]), df_worthy_test[\"class_label\"], average=\"macro\")\n",
    "    print(\"Dummy Precision-Score for {}-gram: {}%\".format(n, round(precision_score * 100, 2)))\n",
    "    \n",
    "    recall_score = metrics.recall_score(dummy_clf.predict(tweet_bow_test[n]), df_worthy_test[\"class_label\"], average=\"macro\")\n",
    "    print(\"Dummy Recall-Score for {}-gram: {}%\".format(n, round(recall_score * 100, 2)))\n",
    "    \n",
    "    print(\"--------Downsampled--------\")\n",
    "    dummy_clf = DummyClassifier(strategy=\"prior\")\n",
    "    dummy_clf.fit(tweet_bow_train_d[n], df_downsampled[\"class_label\"])\n",
    "    print(\"{}-gram Priors: {}\".format(n, dummy_clf.class_prior_))\n",
    "\n",
    "    f1_score = metrics.f1_score(dummy_clf.predict(tweet_bow_test_d[n]), df_worthy_test[\"class_label\"], average=\"weighted\")\n",
    "    print(\"Dummy F1-Score for {}-gram: {}%\".format(n, round(f1_score * 100, 2)))\n",
    "    \n",
    "    precision_score = metrics.precision_score(dummy_clf.predict(tweet_bow_test_d[n]), df_worthy_test[\"class_label\"], average=\"macro\")\n",
    "    print(\"Dummy Precision-Score for {}-gram: {}%\".format(n, round(precision_score * 100, 2)))\n",
    "    \n",
    "    recall_score = metrics.recall_score(dummy_clf.predict(tweet_bow_test_d[n]), df_worthy_test[\"class_label\"], average=\"macro\")\n",
    "    print(\"Dummy Recall-Score for {}-gram: {}%\".format(n, round(recall_score * 100, 2)))\n",
    "    \n",
    "    print(\"--------Upsampled--------\")\n",
    "    dummy_clf = DummyClassifier(strategy=\"prior\")\n",
    "    dummy_clf.fit(tweet_bow_train_u[n], df_upsampled[\"class_label\"])\n",
    "    print(\"{}-gram Priors: {}\".format(n, dummy_clf.class_prior_))\n",
    "\n",
    "    f1_score = metrics.f1_score(dummy_clf.predict(tweet_bow_test_u[n]), df_worthy_test[\"class_label\"], average=\"weighted\")\n",
    "    print(\"Dummy F1-Score for {}-gram: {}%\".format(n, round(f1_score * 100, 2)))\n",
    "    \n",
    "    precision_score = metrics.precision_score(dummy_clf.predict(tweet_bow_test_u[n]), df_worthy_test[\"class_label\"], average=\"macro\")\n",
    "    print(\"Dummy Precision-Score for {}-gram: {}%\".format(n, round(precision_score * 100, 2)))\n",
    "    \n",
    "    recall_score = metrics.recall_score(dummy_clf.predict(tweet_bow_test_u[n]), df_worthy_test[\"class_label\"], average=\"macro\")\n",
    "    print(\"Dummy Recall-Score for {}-gram: {}%\".format(n, round(recall_score * 100, 2)))\n",
    "    \n",
    "    print(\"--------Meansampled--------\")\n",
    "    dummy_clf = DummyClassifier(strategy=\"prior\")\n",
    "    dummy_clf.fit(tweet_bow_train_h[n], df_meansampled[\"class_label\"])\n",
    "    print(\"{}-gram Priors: {}\".format(n, dummy_clf.class_prior_))\n",
    "\n",
    "    f1_score = metrics.f1_score(dummy_clf.predict(tweet_bow_test_h[n]), df_worthy_test[\"class_label\"], average=\"weighted\")\n",
    "    print(\"Dummy F1-Score for {}-gram: {}%\".format(n, round(f1_score * 100, 2)))\n",
    "    \n",
    "    precision_score = metrics.precision_score(dummy_clf.predict(tweet_bow_test_h[n]), df_worthy_test[\"class_label\"], average=\"macro\")\n",
    "    print(\"Dummy Precision-Score for {}-gram: {}%\".format(n, round(precision_score * 100, 2)))\n",
    "    \n",
    "    recall_score = metrics.recall_score(dummy_clf.predict(tweet_bow_test_h[n]), df_worthy_test[\"class_label\"], average=\"macro\")\n",
    "    print(\"Dummy Recall-Score for {}-gram: {}%\".format(n, round(recall_score * 100, 2)))\n",
    "    print(\"--------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_w = LogisticRegression(class_weight=weights)\n",
    "lr_n = LogisticRegression(class_weight=None)\n",
    "\n",
    "lr_d = LogisticRegression(class_weight=None)\n",
    "lr_u = LogisticRegression(class_weight=None)\n",
    "lr_h = LogisticRegression(class_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Custom weight--------\n",
      "Logistic Regression F1-Score for 1-gram: 83.52%\n",
      "Logistic Regression Precision-Score for 1-gram: 24.48%\n",
      "Logistic Regression Recall-Score for 1-gram: 22.38%\n",
      "--------No weight--------\n",
      "Logistic Regression F1-Score for 1-gram: 90.42%\n",
      "Logistic Regression Precision-Score for 1-gram: 14.08%\n",
      "Logistic Regression Recall-Score for 1-gram: 18.24%\n",
      "--------------------------------------\n",
      "--------Custom weight--------\n",
      "Logistic Regression F1-Score for 2-gram: 78.15%\n",
      "Logistic Regression Precision-Score for 2-gram: 25.08%\n",
      "Logistic Regression Recall-Score for 2-gram: 21.84%\n",
      "--------No weight--------\n",
      "Logistic Regression F1-Score for 2-gram: 91.87%\n",
      "Logistic Regression Precision-Score for 2-gram: 11.56%\n",
      "Logistic Regression Recall-Score for 2-gram: 13.49%\n",
      "--------------------------------------\n",
      "--------Custom weight--------\n",
      "Logistic Regression F1-Score for 3-gram: 80.52%\n",
      "Logistic Regression Precision-Score for 3-gram: 13.2%\n",
      "Logistic Regression Recall-Score for 3-gram: 13.31%\n",
      "--------No weight--------\n",
      "Logistic Regression F1-Score for 3-gram: 92.7%\n",
      "Logistic Regression Precision-Score for 3-gram: 11.07%\n",
      "Logistic Regression Recall-Score for 3-gram: 9.69%\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for n in ngram_list:\n",
    "    lr_w.fit(tweet_bow_train[n].toarray(), df_worthy_train[\"class_label\"])\n",
    "    lr_n.fit(tweet_bow_train[n].toarray(), df_worthy_train[\"class_label\"])\n",
    "    \n",
    "    print(\"--------Custom weight--------\")\n",
    "    f1_score = metrics.f1_score(lr_w.predict(tweet_bow_val[n].toarray()), df_worthy_valid[\"class_label\"], average=\"weighted\")\n",
    "    print(\"Logistic Regression F1-Score for {}-gram: {}%\".format(n, round(f1_score * 100, 2)))\n",
    "    \n",
    "    precision_score = metrics.precision_score(lr_w.predict(tweet_bow_val[n].toarray()), df_worthy_valid[\"class_label\"], average=\"macro\")\n",
    "    print(\"Logistic Regression Precision-Score for {}-gram: {}%\".format(n, round(precision_score * 100, 2)))\n",
    "    \n",
    "    recall_score = metrics.recall_score(lr_w.predict(tweet_bow_val[n].toarray()), df_worthy_valid[\"class_label\"], average=\"macro\")\n",
    "    print(\"Logistic Regression Recall-Score for {}-gram: {}%\".format(n, round(recall_score * 100, 2)))\n",
    "    \n",
    "    print(\"--------No weight--------\")\n",
    "    f1_score = metrics.f1_score(lr_n.predict(tweet_bow_val[n].toarray()), df_worthy_valid[\"class_label\"], average=\"weighted\")\n",
    "    print(\"Logistic Regression F1-Score for {}-gram: {}%\".format(n, round(f1_score * 100, 2)))\n",
    "    \n",
    "    precision_score = metrics.precision_score(lr_n.predict(tweet_bow_val[n].toarray()), df_worthy_valid[\"class_label\"], average=\"macro\")\n",
    "    print(\"Logistic Regression Precision-Score for {}-gram: {}%\".format(n, round(precision_score * 100, 2)))\n",
    "    \n",
    "    recall_score = metrics.recall_score(lr_n.predict(tweet_bow_val[n].toarray()), df_worthy_valid[\"class_label\"], average=\"macro\")\n",
    "    print(\"Logistic Regression Recall-Score for {}-gram: {}%\".format(n, round(recall_score * 100, 2)))\n",
    "    print(\"--------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Downsampled--------\n",
      "Logistic Regression F1-Score for 1-gram: 4.96%\n",
      "Logistic Regression Precision-Score for 1-gram: 9.52%\n",
      "Logistic Regression Recall-Score for 1-gram: 11.22%\n",
      "--------Upsampled--------\n",
      "Logistic Regression F1-Score for 1-gram: 82.26%\n",
      "Logistic Regression Precision-Score for 1-gram: 20.17%\n",
      "Logistic Regression Recall-Score for 1-gram: 19.83%\n",
      "--------Meansampled--------\n",
      "Logistic Regression F1-Score for 1-gram: 72.63%\n",
      "Logistic Regression Precision-Score for 1-gram: 27.67%\n",
      "Logistic Regression Recall-Score for 1-gram: 18.72%\n",
      "--------Downsampled--------\n",
      "Logistic Regression F1-Score for 2-gram: 1.87%\n",
      "Logistic Regression Precision-Score for 2-gram: 15.44%\n",
      "Logistic Regression Recall-Score for 2-gram: 9.98%\n",
      "--------Upsampled--------\n",
      "Logistic Regression F1-Score for 2-gram: 84.15%\n",
      "Logistic Regression Precision-Score for 2-gram: 11.95%\n",
      "Logistic Regression Recall-Score for 2-gram: 11.96%\n",
      "--------Meansampled--------\n",
      "Logistic Regression F1-Score for 2-gram: 86.18%\n",
      "Logistic Regression Precision-Score for 2-gram: 13.66%\n",
      "Logistic Regression Recall-Score for 2-gram: 14.41%\n",
      "--------Downsampled--------\n",
      "Logistic Regression F1-Score for 3-gram: 1.94%\n",
      "Logistic Regression Precision-Score for 3-gram: 11.11%\n",
      "Logistic Regression Recall-Score for 3-gram: 0.12%\n",
      "--------Upsampled--------\n",
      "Logistic Regression F1-Score for 3-gram: 87.54%\n",
      "Logistic Regression Precision-Score for 3-gram: 11.71%\n",
      "Logistic Regression Recall-Score for 3-gram: 12.03%\n",
      "--------Meansampled--------\n",
      "Logistic Regression F1-Score for 3-gram: 90.54%\n",
      "Logistic Regression Precision-Score for 3-gram: 11.43%\n",
      "Logistic Regression Recall-Score for 3-gram: 13.44%\n"
     ]
    }
   ],
   "source": [
    "for n in ngram_list:\n",
    "    lr_d.fit(tweet_bow_train_d[n].toarray(), df_downsampled[\"class_label\"])\n",
    "    lr_u.fit(tweet_bow_train_u[n].toarray(), df_upsampled[\"class_label\"])\n",
    "    lr_h.fit(tweet_bow_train_h[n].toarray(), df_meansampled[\"class_label\"])\n",
    "    \n",
    "    print(\"--------Downsampled--------\")\n",
    "    f1_score = metrics.f1_score(lr_d.predict(tweet_bow_val_d[n].toarray()), df_worthy_valid[\"class_label\"], average=\"weighted\")\n",
    "    print(\"Logistic Regression F1-Score for {}-gram: {}%\".format(n, round(f1_score * 100, 2)))\n",
    "    \n",
    "    precision_score = metrics.precision_score(lr_d.predict(tweet_bow_val_d[n].toarray()), df_worthy_valid[\"class_label\"], average=\"macro\")\n",
    "    print(\"Logistic Regression Precision-Score for {}-gram: {}%\".format(n, round(precision_score * 100, 2)))\n",
    "    \n",
    "    recall_score = metrics.recall_score(lr_d.predict(tweet_bow_val_d[n].toarray()), df_worthy_valid[\"class_label\"], average=\"macro\")\n",
    "    print(\"Logistic Regression Recall-Score for {}-gram: {}%\".format(n, round(recall_score * 100, 2)))\n",
    "    \n",
    "    print(\"--------Upsampled--------\")\n",
    "    f1_score = metrics.f1_score(lr_u.predict(tweet_bow_val_u[n].toarray()), df_worthy_valid[\"class_label\"], average=\"weighted\")\n",
    "    print(\"Logistic Regression F1-Score for {}-gram: {}%\".format(n, round(f1_score * 100, 2)))\n",
    "    \n",
    "    precision_score = metrics.precision_score(lr_u.predict(tweet_bow_val_u[n].toarray()), df_worthy_valid[\"class_label\"], average=\"macro\")\n",
    "    print(\"Logistic Regression Precision-Score for {}-gram: {}%\".format(n, round(precision_score * 100, 2)))\n",
    "    \n",
    "    recall_score = metrics.recall_score(lr_u.predict(tweet_bow_val_u[n].toarray()), df_worthy_valid[\"class_label\"], average=\"macro\")\n",
    "    print(\"Logistic Regression Recall-Score for {}-gram: {}%\".format(n, round(recall_score * 100, 2)))\n",
    "    \n",
    "    print(\"--------Meansampled--------\")\n",
    "    f1_score = metrics.f1_score(lr_h.predict(tweet_bow_val_h[n].toarray()), df_worthy_valid[\"class_label\"], average=\"weighted\")\n",
    "    print(\"Logistic Regression F1-Score for {}-gram: {}%\".format(n, round(f1_score * 100, 2)))\n",
    "    \n",
    "    precision_score = metrics.precision_score(lr_h.predict(tweet_bow_val_h[n].toarray()), df_worthy_valid[\"class_label\"], average=\"macro\")\n",
    "    print(\"Logistic Regression Precision-Score for {}-gram: {}%\".format(n, round(precision_score * 100, 2)))\n",
    "    \n",
    "    recall_score = metrics.recall_score(lr_h.predict(tweet_bow_val_h[n].toarray()), df_worthy_valid[\"class_label\"], average=\"macro\")\n",
    "    print(\"Logistic Regression Recall-Score for {}-gram: {}%\".format(n, round(recall_score * 100, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Meansampled--------\n",
      "Logistic Regression F1-Score for 2-gram: 85.84%\n",
      "Logistic Regression Precision-Score for 2-gram: 19.26%\n",
      "Logistic Regression Recall-Score for 2-gram: 21.03%\n"
     ]
    }
   ],
   "source": [
    "n = 2\n",
    "print(\"--------Meansampled--------\")\n",
    "lr_h.fit(tweet_bow_train_h[n].toarray(), df_meansampled[\"class_label\"])\n",
    "f1_score = metrics.f1_score(lr_h.predict(tweet_bow_test_h[n].toarray()), df_worthy_test[\"class_label\"], average=\"weighted\")\n",
    "print(\"Logistic Regression F1-Score for {}-gram: {}%\".format(n, round(f1_score * 100, 2)))\n",
    "    \n",
    "precision_score = metrics.precision_score(lr_h.predict(tweet_bow_test_h[n].toarray()), df_worthy_test[\"class_label\"], average=\"macro\")\n",
    "print(\"Logistic Regression Precision-Score for {}-gram: {}%\".format(n, round(precision_score * 100, 2)))\n",
    "    \n",
    "recall_score = metrics.recall_score(lr_h.predict(tweet_bow_test_h[n].toarray()), df_worthy_test[\"class_label\"], average=\"macro\")\n",
    "print(\"Logistic Regression Recall-Score for {}-gram: {}%\".format(n, round(recall_score * 100, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-nearest neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://iq.opengenus.org/text-classification-using-k-nearest-neighbors/\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=9)#, weights=class_weights)\n",
    "knn_d = KNeighborsClassifier(n_neighbors=9)#, weights=class_weights)\n",
    "knn_u = KNeighborsClassifier(n_neighbors=9)#, weights=class_weights)\n",
    "knn_h = KNeighborsClassifier(n_neighbors=9)#, weights=class_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Unbalanced--------\n",
      "KNN F1-Score for 1-gram: 91.98%\n",
      "KNN Precision-Score for 1-gram: 11.11%\n",
      "KNN Recall-Score for 1-gram: 9.46%\n",
      "--------Downsampled--------\n",
      "KNN F1-Score for 1-gram: 2.3%\n",
      "KNN Precision-Score for 1-gram: 12.15%\n",
      "KNN Recall-Score for 1-gram: 9.37%\n",
      "--------Upsampled--------\n",
      "KNN F1-Score for 1-gram: 76.27%\n",
      "KNN Precision-Score for 1-gram: 13.89%\n",
      "KNN Recall-Score for 1-gram: 11.84%\n",
      "--------Meansampled--------\n",
      "KNN F1-Score for 1-gram: 4.23%\n",
      "KNN Precision-Score for 1-gram: 9.84%\n",
      "KNN Recall-Score for 1-gram: 14.2%\n",
      "--------------------------------------\n",
      "--------Unbalanced--------\n",
      "KNN F1-Score for 2-gram: 91.98%\n",
      "KNN Precision-Score for 2-gram: 11.11%\n",
      "KNN Recall-Score for 2-gram: 9.46%\n",
      "--------Downsampled--------\n",
      "KNN F1-Score for 2-gram: 0.66%\n",
      "KNN Precision-Score for 2-gram: 11.19%\n",
      "KNN Recall-Score for 2-gram: 11.15%\n",
      "--------Upsampled--------\n",
      "KNN F1-Score for 2-gram: 83.65%\n",
      "KNN Precision-Score for 2-gram: 12.88%\n",
      "KNN Recall-Score for 2-gram: 12.09%\n",
      "--------Meansampled--------\n",
      "KNN F1-Score for 2-gram: 91.44%\n",
      "KNN Precision-Score for 2-gram: 10.99%\n",
      "KNN Recall-Score for 2-gram: 9.75%\n",
      "--------------------------------------\n",
      "--------Unbalanced--------\n",
      "KNN F1-Score for 3-gram: 91.65%\n",
      "KNN Precision-Score for 3-gram: 11.08%\n",
      "KNN Recall-Score for 3-gram: 9.46%\n",
      "--------Downsampled--------\n",
      "KNN F1-Score for 3-gram: 0.65%\n",
      "KNN Precision-Score for 3-gram: 11.11%\n",
      "KNN Recall-Score for 3-gram: 0.04%\n",
      "--------Upsampled--------\n",
      "KNN F1-Score for 3-gram: 16.53%\n",
      "KNN Precision-Score for 3-gram: 11.24%\n",
      "KNN Recall-Score for 3-gram: 11.12%\n",
      "--------Meansampled--------\n",
      "KNN F1-Score for 3-gram: 92.15%\n",
      "KNN Precision-Score for 3-gram: 11.56%\n",
      "KNN Recall-Score for 3-gram: 13.42%\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for n in ngram_list:\n",
    "    knn.fit(tweet_bow_train[n].toarray(), df_worthy_train[\"class_label\"])\n",
    "    knn_d.fit(tweet_bow_train_d[n].toarray(), df_downsampled[\"class_label\"])\n",
    "    knn_u.fit(tweet_bow_train_u[n].toarray(), df_upsampled[\"class_label\"])\n",
    "    knn_h.fit(tweet_bow_train_h[n].toarray(), df_meansampled[\"class_label\"])\n",
    "    \n",
    "    print(\"--------Unbalanced--------\")\n",
    "    f1_score = metrics.f1_score(knn.predict(tweet_bow_test[n].toarray()), df_worthy_test[\"class_label\"], average=\"weighted\")\n",
    "    print(\"KNN F1-Score for {}-gram: {}%\".format(n, round(f1_score * 100, 2)))\n",
    "    \n",
    "    precision_score = metrics.precision_score(knn.predict(tweet_bow_test[n].toarray()), df_worthy_test[\"class_label\"], average=\"macro\")\n",
    "    print(\"KNN Precision-Score for {}-gram: {}%\".format(n, round(precision_score * 100, 2)))\n",
    "    \n",
    "    recall_score = metrics.recall_score(knn.predict(tweet_bow_test[n].toarray()), df_worthy_test[\"class_label\"], average=\"macro\")\n",
    "    print(\"KNN Recall-Score for {}-gram: {}%\".format(n, round(recall_score * 100, 2)))\n",
    "    \n",
    "    print(\"--------Downsampled--------\")\n",
    "    f1_score = metrics.f1_score(knn_d.predict(tweet_bow_val_d[n].toarray()), df_worthy_valid[\"class_label\"], average=\"weighted\")\n",
    "    print(\"KNN F1-Score for {}-gram: {}%\".format(n, round(f1_score * 100, 2)))\n",
    "    \n",
    "    precision_score = metrics.precision_score(knn_d.predict(tweet_bow_val_d[n].toarray()), df_worthy_valid[\"class_label\"], average=\"macro\")\n",
    "    print(\"KNN Precision-Score for {}-gram: {}%\".format(n, round(precision_score * 100, 2)))\n",
    "    \n",
    "    recall_score = metrics.recall_score(knn_d.predict(tweet_bow_val_d[n].toarray()), df_worthy_valid[\"class_label\"], average=\"macro\")\n",
    "    print(\"KNN Recall-Score for {}-gram: {}%\".format(n, round(recall_score * 100, 2)))\n",
    "    \n",
    "    print(\"--------Upsampled--------\")\n",
    "    f1_score = metrics.f1_score(knn_u.predict(tweet_bow_val_u[n].toarray()), df_worthy_valid[\"class_label\"], average=\"weighted\")\n",
    "    print(\"KNN F1-Score for {}-gram: {}%\".format(n, round(f1_score * 100, 2)))\n",
    "    \n",
    "    precision_score = metrics.precision_score(knn_u.predict(tweet_bow_val_u[n].toarray()), df_worthy_valid[\"class_label\"], average=\"macro\")\n",
    "    print(\"KNN Precision-Score for {}-gram: {}%\".format(n, round(precision_score * 100, 2)))\n",
    "    \n",
    "    recall_score = metrics.recall_score(knn_u.predict(tweet_bow_val_u[n].toarray()), df_worthy_valid[\"class_label\"], average=\"macro\")\n",
    "    print(\"KNN Recall-Score for {}-gram: {}%\".format(n, round(recall_score * 100, 2)))\n",
    "    \n",
    "    print(\"--------Meansampled--------\")\n",
    "    f1_score = metrics.f1_score(knn_h.predict(tweet_bow_val_h[n].toarray()), df_worthy_valid[\"class_label\"], average=\"weighted\")\n",
    "    print(\"KNN F1-Score for {}-gram: {}%\".format(n, round(f1_score * 100, 2)))\n",
    "    \n",
    "    precision_score = metrics.precision_score(knn_h.predict(tweet_bow_val_h[n].toarray()), df_worthy_valid[\"class_label\"], average=\"macro\")\n",
    "    print(\"KNN Precision-Score for {}-gram: {}%\".format(n, round(precision_score * 100, 2)))\n",
    "    \n",
    "    recall_score = metrics.recall_score(knn_h.predict(tweet_bow_val_h[n].toarray()), df_worthy_valid[\"class_label\"], average=\"macro\")\n",
    "    print(\"KNN Recall-Score for {}-gram: {}%\".format(n, round(recall_score * 100, 2)))\n",
    "    print(\"--------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Meansampled--------\n",
      "KNN F1-Score for 3-gram: 91.53%\n",
      "KNN Precision-Score for 3-gram: 11.59%\n",
      "KNN Recall-Score for 3-gram: 24.3%\n"
     ]
    }
   ],
   "source": [
    "n = 3\n",
    "print(\"--------Meansampled--------\")\n",
    "f1_score = metrics.f1_score(knn_h.predict(tweet_bow_test_h[n].toarray()), df_worthy_test[\"class_label\"], average=\"weighted\")\n",
    "print(\"KNN F1-Score for {}-gram: {}%\".format(n, round(f1_score * 100, 2)))\n",
    "    \n",
    "precision_score = metrics.precision_score(knn_h.predict(tweet_bow_test_h[n].toarray()), df_worthy_test[\"class_label\"], average=\"macro\")\n",
    "print(\"KNN Precision-Score for {}-gram: {}%\".format(n, round(precision_score * 100, 2)))\n",
    "    \n",
    "recall_score = metrics.recall_score(knn_h.predict(tweet_bow_test_h[n].toarray()), df_worthy_test[\"class_label\"], average=\"macro\")\n",
    "print(\"KNN Recall-Score for {}-gram: {}%\".format(n, round(recall_score * 100, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Unbalanced--------\n",
      "Complement F1-Score for 1-gram: 81.31%\n",
      "Complement precision for 1-gram: 25.06%\n",
      "Complement recall for 1-gram: 25.45%\n",
      "--------Downsampled--------\n",
      "KNN F1-Score for 1-gram: 7.59%\n",
      "KNN Precision-Score for 1-gram: 8.43%\n",
      "KNN Recall-Score for 1-gram: 11.26%\n",
      "--------Upsampled--------\n",
      "Complement F1-Score for 1-gram: 81.7%\n",
      "Complement precision for 1-gram: 24.19%\n",
      "Complement recall for 1-gram: 11.7%\n",
      "--------Meansampled--------\n",
      "KNN F1-Score for 1-gram: 54.2%\n",
      "KNN Precision-Score for 1-gram: 31.58%\n",
      "KNN Recall-Score for 1-gram: 17.25%\n",
      "--------------------------------------\n",
      "--------Unbalanced--------\n",
      "Complement F1-Score for 2-gram: 71.3%\n",
      "Complement precision for 2-gram: 20.27%\n",
      "Complement recall for 2-gram: 18.08%\n",
      "--------Downsampled--------\n",
      "KNN F1-Score for 2-gram: 8.12%\n",
      "KNN Precision-Score for 2-gram: 13.28%\n",
      "KNN Recall-Score for 2-gram: 11.41%\n",
      "--------Upsampled--------\n",
      "Complement F1-Score for 2-gram: 67.52%\n",
      "Complement precision for 2-gram: 24.08%\n",
      "Complement recall for 2-gram: 11.74%\n",
      "--------Meansampled--------\n",
      "KNN F1-Score for 2-gram: 45.5%\n",
      "KNN Precision-Score for 2-gram: 22.94%\n",
      "KNN Recall-Score for 2-gram: 15.33%\n",
      "--------------------------------------\n",
      "--------Unbalanced--------\n",
      "Complement F1-Score for 3-gram: 39.59%\n",
      "Complement precision for 3-gram: 15.58%\n",
      "Complement recall for 3-gram: 16.63%\n",
      "--------Downsampled--------\n",
      "KNN F1-Score for 3-gram: 11.52%\n",
      "KNN Precision-Score for 3-gram: 10.05%\n",
      "KNN Recall-Score for 3-gram: 0.79%\n",
      "--------Upsampled--------\n",
      "Complement F1-Score for 3-gram: 15.33%\n",
      "Complement precision for 3-gram: 12.13%\n",
      "Complement recall for 3-gram: 16.73%\n",
      "--------Meansampled--------\n",
      "KNN F1-Score for 3-gram: 11.54%\n",
      "KNN Precision-Score for 3-gram: 10.04%\n",
      "KNN Recall-Score for 3-gram: 11.97%\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB # suited for classification with discrete features\n",
    "from sklearn.naive_bayes import ComplementNB \n",
    "\n",
    "clf = ComplementNB()\n",
    "clf_d = MultinomialNB()\n",
    "clf_u = MultinomialNB()\n",
    "clf_h = MultinomialNB()\n",
    "\n",
    "for n in ngram_list:\n",
    "    print(\"--------Unbalanced--------\")\n",
    "    clf.fit(tweet_bow_train[n].toarray(), df_worthy_train[\"class_label\"])\n",
    "    f1_score = metrics.f1_score(clf.predict(tweet_bow_test[n].toarray()), df_worthy_test[\"class_label\"], average=\"weighted\")\n",
    "    print(\"Complement F1-Score for {}-gram: {}%\".format(n, round(f1_score * 100, 2)))\n",
    "    \n",
    "    precision_score = metrics.precision_score(clf.predict(tweet_bow_test[n].toarray()), df_worthy_test[\"class_label\"], average=\"macro\")\n",
    "    print(\"Complement precision for {}-gram: {}%\".format(n, round(precision_score * 100, 2)))\n",
    "    \n",
    "    recall_score = metrics.recall_score(clf.predict(tweet_bow_test[n].toarray()), df_worthy_test[\"class_label\"], average=\"macro\")\n",
    "    print(\"Complement recall for {}-gram: {}%\".format(n, round(recall_score * 100, 2)))\n",
    "    \n",
    "    print(\"--------Downsampled--------\")\n",
    "    clf_d.fit(tweet_bow_train_d[n].toarray(), df_downsampled[\"class_label\"])\n",
    "    f1_score = metrics.f1_score(clf_d.predict(tweet_bow_val_d[n].toarray()), df_worthy_valid[\"class_label\"], average=\"weighted\")\n",
    "    print(\"KNN F1-Score for {}-gram: {}%\".format(n, round(f1_score * 100, 2)))\n",
    "    \n",
    "    precision_score = metrics.precision_score(clf_d.predict(tweet_bow_val_d[n].toarray()), df_worthy_valid[\"class_label\"], average=\"macro\")\n",
    "    print(\"KNN Precision-Score for {}-gram: {}%\".format(n, round(precision_score * 100, 2)))\n",
    "    \n",
    "    recall_score = metrics.recall_score(clf_d.predict(tweet_bow_val_d[n].toarray()), df_worthy_valid[\"class_label\"], average=\"macro\")\n",
    "    print(\"KNN Recall-Score for {}-gram: {}%\".format(n, round(recall_score * 100, 2)))\n",
    "    \n",
    "    print(\"--------Upsampled--------\")\n",
    "    clf_u.fit(tweet_bow_train_u[n].toarray(), df_upsampled[\"class_label\"])\n",
    "    f1_score = metrics.f1_score(clf_u.predict(tweet_bow_val_u[n].toarray()), df_worthy_valid[\"class_label\"], average=\"weighted\")\n",
    "    print(\"Complement F1-Score for {}-gram: {}%\".format(n, round(f1_score * 100, 2)))\n",
    "    \n",
    "    precision_score = metrics.precision_score(clf_u.predict(tweet_bow_val_u[n].toarray()), df_worthy_valid[\"class_label\"], average=\"macro\")\n",
    "    print(\"Complement precision for {}-gram: {}%\".format(n, round(precision_score * 100, 2)))\n",
    "    \n",
    "    recall_score = metrics.recall_score(clf.predict(tweet_bow_val_u[n].toarray()), df_worthy_valid[\"class_label\"], average=\"macro\")\n",
    "    print(\"Complement recall for {}-gram: {}%\".format(n, round(recall_score * 100, 2)))\n",
    "    \n",
    "    print(\"--------Meansampled--------\")\n",
    "    clf_h.fit(tweet_bow_train_h[n].toarray(), df_meansampled[\"class_label\"])\n",
    "    f1_score = metrics.f1_score(clf_h.predict(tweet_bow_val_h[n].toarray()), df_worthy_valid[\"class_label\"], average=\"weighted\")\n",
    "    print(\"KNN F1-Score for {}-gram: {}%\".format(n, round(f1_score * 100, 2)))\n",
    "    \n",
    "    precision_score = metrics.precision_score(clf_h.predict(tweet_bow_val_h[n].toarray()), df_worthy_valid[\"class_label\"], average=\"macro\")\n",
    "    print(\"KNN Precision-Score for {}-gram: {}%\".format(n, round(precision_score * 100, 2)))\n",
    "    \n",
    "    recall_score = metrics.recall_score(clf_h.predict(tweet_bow_val_h[n].toarray()), df_worthy_valid[\"class_label\"], average=\"macro\")\n",
    "    print(\"KNN Recall-Score for {}-gram: {}%\".format(n, round(recall_score * 100, 2)))\n",
    "    print(\"--------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Upsampled--------\n",
      "Complement F1-Score for 1-gram: 78.42%\n",
      "Complement precision for 1-gram: 26.54%\n",
      "Complement recall for 1-gram: 11.25%\n"
     ]
    }
   ],
   "source": [
    "n = 1\n",
    "print(\"--------Upsampled--------\")\n",
    "clf_u.fit(tweet_bow_train_u[n].toarray(), df_upsampled[\"class_label\"])\n",
    "f1_score = metrics.f1_score(clf_u.predict(tweet_bow_test_u[n].toarray()), df_worthy_test[\"class_label\"], average=\"weighted\")\n",
    "print(\"Complement F1-Score for {}-gram: {}%\".format(n, round(f1_score * 100, 2)))\n",
    "    \n",
    "precision_score = metrics.precision_score(clf_u.predict(tweet_bow_test_u[n].toarray()), df_worthy_test[\"class_label\"], average=\"macro\")\n",
    "print(\"Complement precision for {}-gram: {}%\".format(n, round(precision_score * 100, 2)))\n",
    "    \n",
    "recall_score = metrics.recall_score(clf.predict(tweet_bow_test_u[n].toarray()), df_worthy_test[\"class_label\"], average=\"macro\")\n",
    "print(\"Complement recall for {}-gram: {}%\".format(n, round(recall_score * 100, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "<hr>\n",
    "\n",
    "\n",
    "# (Multi-Class) Text Classification using Bidirectional LSTM\n",
    "\n",
    "Source: https://medium.com/analytics-vidhya/author-multi-class-text-classification-using-bidirectional-lstm-keras-c9a533a1cc4a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from tqdm import tqdm\n",
    "from keras.models import Sequential\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import GlobalMaxPooling1D, Conv1D, MaxPooling1D, Flatten, Bidirectional, SpatialDropout1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLemmText(text):\n",
    " tokens=word_tokenize(text)\n",
    " lemmatizer = WordNetLemmatizer()\n",
    " tokens=[lemmatizer.lemmatize(word) for word in tokens]\n",
    " return \" \".join(tokens)\n",
    "df_worthy_train[\"tweet_text\"] = list(map(getLemmText, df_worthy_train[\"tweet_text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIMENSION = 64\n",
    "VOCABULARY_SIZE = 16000\n",
    "MAX_LENGTH = 100\n",
    "OOV_TOK = '<OOV>'\n",
    "TRUNCATE_TYPE = 'post'\n",
    "PADDING_TYPE = 'post'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=VOCABULARY_SIZE, oov_token=OOV_TOK)\n",
    "tokenizer.fit_on_texts(list(df_worthy_train[\"tweet_text\"]) + list(df_worthy_train[\"class_label\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 15745\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'<OOV>': 1,\n",
       " 'the': 2,\n",
       " 'and': 3,\n",
       " 'vaccine': 4,\n",
       " 't': 5,\n",
       " 'co': 6,\n",
       " 'to': 7,\n",
       " 'http': 8,\n",
       " 'not': 9,\n",
       " 'no': 10}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_sequences = tokenizer.texts_to_sequences(df_worthy_train[\"tweet_text\"])\n",
    "xtest_sequences = tokenizer.texts_to_sequences(df_worthy_train[\"class_label\"])\n",
    "word_index = tokenizer.word_index\n",
    "print('Vocabulary size:', len(word_index))\n",
    "dict(list(word_index.items())[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40, 50, 369, 24, 5, 1084, 70, 4, 122, 3, 70, 351, 257, 122, 26, 2, 158, 7, 90, 36, 2, 521, 72, 317, 17, 12, 14, 3696]\n"
     ]
    }
   ],
   "source": [
    "print(xtrain_sequences[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n",
      "100\n",
      "[  40   50  369   24    5 1084   70    4  122    3   70  351  257  122\n",
      "   26    2  158    7   90   36    2  521   72  317   17   12   14 3696\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n"
     ]
    }
   ],
   "source": [
    "xtrain_pad = sequence.pad_sequences(xtrain_sequences, maxlen=MAX_LENGTH, padding=PADDING_TYPE, truncating=TRUNCATE_TYPE)\n",
    "xtest_pad = sequence.pad_sequences(xtest_sequences, maxlen=MAX_LENGTH, padding=PADDING_TYPE, truncating=TRUNCATE_TYPE)\n",
    "print(len(xtrain_sequences[0]))\n",
    "print(len(xtrain_pad[0]))\n",
    "print(xtrain_pad[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1051, 607, 147, 19, 70, 1052, 415, 30, 8, 10, 42, 200, 6, 1, 416, 29, 1053, 2, 1054, 608, 18, 1055, 417, 1056, 2, 1057, 416, 251, 20, 64, 418, 96, 7, 19, 419, 70, 113, 18, 20, 17, 1, 201]\n",
      "[1058, 609, 420, 14, 56, 307, 8, 10, 7, 11, 1059, 6, 202, 308, 309, 1060, 2, 1061, 89, 2, 119, 5, 3, 4, 1062]\n",
      "[8, 10, 25, 1063, 22, 201, 9, 252, 2, 18, 8, 10, 7, 77, 6, 421, 2, 159, 6, 160, 23, 14, 22, 148, 6, 422, 65, 22, 1064, 2, 97, 22, 161, 5, 3, 4, 1065]\n",
      "(306,)\n"
     ]
    }
   ],
   "source": [
    "label_tokenizer = Tokenizer()\n",
    "label_tokenizer.fit_on_texts(list(df_worthy_valid[\"tweet_text\"]))\n",
    "training_label_seq = np.array(label_tokenizer.texts_to_sequences(df_worthy_valid[\"tweet_text\"]))\n",
    "test_label_seq = np.array(label_tokenizer.texts_to_sequences(df_worthy_valid[\"class_label\"]))\n",
    "print(training_label_seq[0])\n",
    "print(training_label_seq[1])\n",
    "print(training_label_seq[2])\n",
    "print(training_label_seq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dear moms for the love of god and family do not let anyone jab your baby with the experimental covid 19 vaccine http t co 0lizf4drgq ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?\n"
     ]
    }
   ],
   "source": [
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "def decode_article(text):\n",
    " return \" \".join([reverse_word_index.get(i, \"?\") for i in text])\n",
    "print(decode_article(xtrain_pad[11]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(len(word_index) + 1,\n",
    "                     EMBEDDING_DIMENSION))\n",
    "model.add(SpatialDropout1D(0.3))\n",
    "model.add(Bidirectional(LSTM(EMBEDDING_DIMENSION, dropout=0.3, recurrent_dropout=0.3)))\n",
    "model.add(Dense(EMBEDDING_DIMENSION, activation='relu'))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Dense(EMBEDDING_DIMENSION, activation='relu'))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: below codeblock doesnt work due to these two fucks having the wrong datatype\n",
    "#xtrain_pad = np.asarray(xtrain_pad).astype(np.int_)\n",
    "xtrain_pad = np.asarray(xtrain_pad).astype('float32')\n",
    "\n",
    "#training_label_seq\n",
    "\n",
    "#these too?\n",
    "#xtest_pad\n",
    "#test_label_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3321, 100)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(306,)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_label_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type list).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15216/1535274853.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtrain_pad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_label_seq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtest_pad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_label_seq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\minh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\minh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    100\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m   \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type list)."
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "history = model.fit(xtrain_pad, training_label_seq, epochs=num_epochs, validation_data=(xtest_pad, test_label_seq), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/ivarw/Dropbox/GitDAT550/Final_Project/1d.ipynb Cell 60'\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ivarw/Dropbox/GitDAT550/Final_Project/1d.ipynb#ch0000062?line=5'>6</a>\u001b[0m   plt\u001b[39m.\u001b[39mlegend([string, \u001b[39m'\u001b[39m\u001b[39mval_\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39mstring])\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ivarw/Dropbox/GitDAT550/Final_Project/1d.ipynb#ch0000062?line=6'>7</a>\u001b[0m   plt\u001b[39m.\u001b[39mshow()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ivarw/Dropbox/GitDAT550/Final_Project/1d.ipynb#ch0000062?line=8'>9</a>\u001b[0m graph_plots(history, \u001b[39m\"\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ivarw/Dropbox/GitDAT550/Final_Project/1d.ipynb#ch0000062?line=9'>10</a>\u001b[0m graph_plots(history, \u001b[39m\"\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "def graph_plots(history, string):\n",
    "  plt.plot(history.history[string])\n",
    "  plt.plot(history.history['val_'+string])\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(string)\n",
    "  plt.legend([string, 'val_'+string])\n",
    "  plt.show()\n",
    "  \n",
    "graph_plots(history, \"accuracy\")\n",
    "graph_plots(history, \"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8bb7827f47cd248081edd9fae95b0b9fdd57b4fc1bdee42bda07c6c0f696abf2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
