{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subtask B: Verifiable factual claims detection: Given a tweet, predict whether it contains a verifiable factual claim. This is a binary task with two labels: Yes and No. This is a classification task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check this: \n",
    "- https://github.com/avirup88/Binary-Classification-using-N-Gram-Model-on-Text-Data\n",
    "- https://stackoverflow.com/questions/48003907/how-to-train-naive-bayes-classifier-for-n-gram-movie-reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import nltk.classify.util\n",
    "from nltk.classify import NaiveBayesClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/1b/CT22_english_1B_claim_train.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"class_label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_df = df.loc[df['class_label'] == 1]\n",
    "true_df_1000 = true_df[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_df = df.loc[df['class_label'] == 0]\n",
    "false_df_1000 = true_df[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [true_df_1000, false_df_1000]\n",
    "df_v2 = pd.concat(frames)\n",
    "df_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_label = df[\"class_label\"].values\n",
    "#class_label = df_v2[\"class_label\"].values\n",
    "class_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_txt = df[\"tweet_text\"].values\n",
    "#tweet_txt = df_v2[\"tweet_text\"].values\n",
    "tweet_txt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(tweet_txt)\n",
    "df1 = df1.rename(columns={0:'tweet'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(class_label)\n",
    "df2 = df2.rename(columns={0:'label'})\n",
    "new_df = pd.concat([df1, df2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(article):\n",
    "    doc_list = []\n",
    "    for art in article:\n",
    "        art = re.sub('[^A-Za-z0-9]+', ' ', art.lower())\n",
    "        content_tokens = word_tokenize(art)\n",
    "        doc = [word for word in  content_tokens if not word.lower() in stop_words]\n",
    "        doc = [n for n in doc if not n.isdigit()]\n",
    "        doc_list.append(\" \".join(doc))\n",
    "        \n",
    "    return doc_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['tweet'] = preprocess(new_df['tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_words = pd.read_csv(\"words.txt\", sep=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blacklisted = [\"http\", \"https\", \"co\", \"twitter\", \"com\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def getNgrams(words, n = 2):\n",
    "#     wordList = []\n",
    "#     for i in words.split():\n",
    "#         if i in eng_words.values:\n",
    "#             wordList.append(i)\n",
    "#     ngram_vocab = ngrams(wordList, n)\n",
    "#     my_dict = dict([(ng, True) for ng in ngram_vocab])  \n",
    "#     return my_dict  \n",
    "  \n",
    "    \n",
    "# def getNgrams(words, n = 2):\n",
    "#     ngram_vocab = ngrams(words.split(), n)\n",
    "#     my_dict = dict([(ng, True) for ng in ngram_vocab])  \n",
    "#     return my_dict  \n",
    "  \n",
    "  \n",
    "def getNgrams(words, n = 2):\n",
    "    wordList = []\n",
    "    for i in words.split():\n",
    "        if i not in blacklisted:\n",
    "            wordList.append(i)\n",
    "    ngram_vocab = ngrams(wordList, n)\n",
    "    my_dict = dict([(ng, True) for ng in ngram_vocab])  \n",
    "    return my_dict  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultDict = {}\n",
    "\n",
    "for n in [1,2,3,4,5]:\n",
    "    trueList = []\n",
    "    falseList = []\n",
    "    for line in new_df[new_df.label == 1].tweet:\n",
    "        trueList.append((getNgrams(line, n), 'true'))\n",
    "    for line in new_df[new_df.label == 0].tweet:\n",
    "        falseList.append((getNgrams(line, n), 'false'))\n",
    "    \n",
    "    trainset = trueList + falseList\n",
    "        \n",
    "    classifier = NaiveBayesClassifier.train(trainset)\n",
    "    \n",
    "    resultDict[n] = classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess of test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"data/1b/CT22_english_1B_claim_dev_test.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_label_test = test_df[\"class_label\"].values\n",
    "tweet_txt_test = test_df[\"tweet_text\"].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_test = pd.DataFrame(tweet_txt_test)\n",
    "df1_test = df1_test.rename(columns={0:'tweet'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_test = pd.DataFrame(class_label_test)\n",
    "df2_test = df2_test.rename(columns={0:'label'})\n",
    "new_test_df = pd.concat([df1_test, df2_test], axis=1)\n",
    "new_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test_df['tweet'] = preprocess(new_test_df['tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_resultDict = {}\n",
    "\n",
    "for n in [1,2,3,4,5]:\n",
    "    trueList = []\n",
    "    falseList = []\n",
    "    for line in new_test_df[new_test_df.label == 1].tweet:\n",
    "        trueList.append((getNgrams(line, n), 'true'))\n",
    "    for line in new_test_df[new_test_df.label == 0].tweet:\n",
    "        falseList.append((getNgrams(line, n), 'false'))\n",
    "        \n",
    "    testset = trueList + falseList\n",
    "    \n",
    "    test_resultDict[n] = testset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in test_resultDict:\n",
    "    classifier = resultDict[n]\n",
    "    testset = test_resultDict[n]\n",
    "    accuracy = nltk.classify.util.accuracy(classifier, testset)\n",
    "    print(str(n)+ '-gram accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "clf = ComplementNB()\n",
    "X = new_df.drop([\"label\"], axis = 1)\n",
    "Y = new_df[\"label\"]\n",
    "\n",
    "X_dict = {}\n",
    "for n in [1,2,3,4,5]:\n",
    "    X_List = []\n",
    "    for x in X.values:\n",
    "        X_List.append(str(getNgrams(x[0], n)))\n",
    "    X_dict[n] = X_List\n",
    "    \n",
    "asdf = pd.DataFrame.from_dict(X_dict)\n",
    "ayo = new_df.join(asdf, how=\"left\")\n",
    "\n",
    "docs = ayo[1].values\n",
    "\n",
    "vec = CountVectorizer()\n",
    "X1 = vec.fit_transform(docs)\n",
    "\n",
    "df1 = pd.DataFrame(X1.toarray(), columns=vec.get_feature_names())\n",
    "\n",
    "clf.fit(df1, Y)\n",
    "print(clf.predict(df1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_test = new_test_df.drop([\"label\"], axis = 1)\n",
    "Y_test = new_test_df[\"label\"]\n",
    "\n",
    "X_test_dict = {}\n",
    "for n in [1,2,3,4,5]:\n",
    "    X_List = []\n",
    "    for x in X.values:\n",
    "        X_List.append(str(getNgrams(x[0], n)))\n",
    "    X_test_dict[n] = X_List\n",
    "    \n",
    "asdf2 = pd.DataFrame.from_dict(X_test_dict)\n",
    "ayo2 = new_test_df.join(asdf2, how=\"left\")\n",
    "\n",
    "docs2 = ayo2[1].values\n",
    "X1_test = vec.fit_transform(docs2)\n",
    "\n",
    "df1_test = pd.DataFrame(X1_test.toarray(), columns=vec.get_feature_names())\n",
    "\n",
    "clf.score(df1_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(911, 6215)"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3324, 15162)"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cd24510e72a5417feea7cb81402ffb6b313add9a2ff74c45dc5472ac7fbe8a4b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
