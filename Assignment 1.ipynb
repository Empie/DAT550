{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0163b57",
   "metadata": {},
   "source": [
    "Assignment 1 - Building a Random Forest\n",
    "This is a skeleton of a Random Forest classifier.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "b9c04941",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import math\n",
    "from statistics import median, mode, mean\n",
    "from collections import Counter\n",
    "from enum import Enum\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f599844",
   "metadata": {},
   "source": [
    "Some simple type definitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "41d87eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttrType(Enum):\n",
    "    cat = 0  # categorical (qualitative) attribute\n",
    "    num = 1  # numerical (quantitative) attribute\n",
    "    target = 2  # target label\n",
    "\n",
    "class NodeType(Enum):\n",
    "    root = 0\n",
    "    internal = 1\n",
    "    leaf = 2\n",
    "\n",
    "class SplitType(Enum):\n",
    "    bin = 0  # binary split\n",
    "    multi = 1  # multi-way split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6b985b",
   "metadata": {},
   "source": [
    "Also, some basic classes to represent an attribute, a spltting procedure, and a node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "4ff84975",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attribute(object):\n",
    "    def __init__(self, label, type):\n",
    "        assert type in AttrType\n",
    "        self.label = label\n",
    "        self.type = type\n",
    "        self.stat = None  # holds mean for numerical and mode for categorical attributes\n",
    "\n",
    "\n",
    "class Splitting(object):\n",
    "    def __init__(self, attr, infogain, split_type, cond, splits):\n",
    "        self.attr = attr  # attribute ID (index in ATTR)\n",
    "        self.infogain = infogain  # information gain if splitting is done on this attribute\n",
    "        self.split_type = split_type  # one of SplitType\n",
    "        self.cond = cond  # splitting condition, i.e., values on outgoing edges\n",
    "        self.splits = splits  # list of training records (IDs) for each slitting condition\n",
    "\n",
    "\n",
    "class Node(object):\n",
    "    def __init__(self, id, type, parent_id, children=None, edge_value=None, val=None, split_type=None, split_cond=None,\n",
    "                 infogain=None):\n",
    "        self.id = id  # ID (same as the index in DT.model list)\n",
    "        self.type = type  # one of NodeType\n",
    "        self.parent_id = parent_id  # ID of parent node (None if root)\n",
    "        self.children = children  # list of IDs of child nodes\n",
    "        self.edge_value = edge_value  # the value of the incoming edge (only if not root node)\n",
    "        self.val = val  # if root or internal node: the attribute that is compared at that node; if leaf node: the target value\n",
    "        self.split_type = split_type  # one of SplitType\n",
    "        self.split_cond = split_cond  # splitting condition (median value for binary splits on numerical values; otherwise a list of categorical values (corresponding to child nodes))\n",
    "        self.infogain = infogain\n",
    "\n",
    "    def append_child(self, node_id):\n",
    "        self.children.append(node_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "fd5166b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('housing_price_train.csv')\n",
    "df['LotFrontage'] = df['LotFrontage'].fillna(df['LotFrontage'].median())\n",
    "df.set_index('Id')\n",
    "df.to_csv('housing_price_train1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "b111ac50",
   "metadata": {},
   "outputs": [],
   "source": [
    "ATTR = []\n",
    "INFILE = \"housing_price_train1.csv\"\n",
    "\n",
    "for col in df.columns:\n",
    "    if col == \"SalePrice\":\n",
    "        ATTR.append(Attribute(col, AttrType.target))\n",
    "    elif col == \"MSSubClass\" or col == \"OverallQual\" or col == \"OverallCond\":\n",
    "        ATTR.append(Attribute(col, AttrType.cat))\n",
    "    elif df[col].unique().dtype == \"int64\" or df[col].unique().dtype == \"float64\":\n",
    "        ATTR.append(Attribute(col, AttrType.num))        \n",
    "    else:\n",
    "        ATTR.append(Attribute(col, AttrType.cat))\n",
    "\n",
    "IDX_TARGET = len(ATTR) - 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d4b0a0",
   "metadata": {},
   "source": [
    "A class DT representing the decision tree classifier. It could represent with methods:\n",
    "\n",
    "a given impurity measure;\n",
    "the search for the best attribute to split with;\n",
    "the addition of a node to the tree;\n",
    "a convenient model printer;\n",
    "the recursive call for obtaining a tree;\n",
    "a builder and an applier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "a5d23f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DT(object):\n",
    "    def __init__(self):\n",
    "        self.data = None  # training data set (loaded into memory)\n",
    "        self.model = None  # decision tree model\n",
    "        # self.default_target = 0.0  # default target class HVA ER DET FOR NOE?\n",
    "\n",
    "    def __load_data(self):\n",
    "        # with open(INFILE) as csvfile:\n",
    "        #     self.data = []\n",
    "        #     csvreader = csv.reader(csvfile, delimiter=',')\n",
    "        #     next(csvreader)\n",
    "        #     for row in csvreader:\n",
    "        #         rec = []\n",
    "        #         for i in range(len(ATTR)):\n",
    "        #             val = row[i].strip()\n",
    "        #             # convert numerical attributes\n",
    "        #             if ATTR[i].type == AttrType.num:  # Note that this will break for \"?\" (missing attribute)\n",
    "        #                 if val == \"\":\n",
    "        #                     val = None\n",
    "        #                 else:\n",
    "        #                     val = float(val)\n",
    "        #             rec.append(val)\n",
    "        #         self.data.append(rec)\n",
    "        #     # print(self.data)\n",
    "        #         # self.data.append([element.strip() for element in row])  # strip spaces\n",
    "        self.data = df.values.tolist()\n",
    "                \n",
    "    def __median(self, a):\n",
    "        # numList = []\n",
    "        # for x in range(a):\n",
    "        #     numList.append(x)\n",
    "        # if len(numList) > 0:\n",
    "        #     return statistics.median(numList)\n",
    "        # else:\n",
    "        #     return 0\n",
    "        all_attribute_values = []\n",
    "        for idx in range(len(self.data)):\n",
    "            all_attribute_values.append(self.data[idx][a])\n",
    "        return statistics.median(all_attribute_values)\n",
    "\n",
    "    # HVA BRUKES DETTE TIL?\n",
    "    # def __mean_squared_error(self, records):\n",
    "    #     \"\"\"\n",
    "    #     Calculates mean squared error for a selection of records.\n",
    "\n",
    "    #     :param records: Data records (given by indices)\n",
    "    #     \"\"\"\n",
    "    #     # TODO\n",
    "    #     #print(records)\n",
    "    #     return 0\n",
    "        \n",
    "    def __find_best_attr(self, attrs, records):\n",
    "        \"\"\"\n",
    "        Finds the attribute with the largest gain.\n",
    "\n",
    "        :param attrs: Set of attributes\n",
    "        :param records: Training set (list of record ids)\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # mse_p = self.__mean_squared_error(records)  # parent's MSE HVORFOR TRENGER VI DEN?\n",
    "        splittings = []  # holds the splitting information for each attribute\n",
    "\n",
    "        for a in attrs:\n",
    "            assert ATTR[a].type in AttrType\n",
    "            splits = {}  # record IDs corresponding to each split\n",
    "            # splitting condition depends on the attribute type\n",
    "            if ATTR[a].type == AttrType.target:  # skip target attribute\n",
    "                continue\n",
    "            elif ATTR[a].type == AttrType.cat:  # categorical attribute\n",
    "                # multi-way split on each possible value\n",
    "                split_mode = SplitType.multi\n",
    "                # each possible attr value corresponds to a split (indexed with categorical labels)\n",
    "                # Note: it's important to consider attr values from the entire training set\n",
    "                split_cond = set([self.data[idx][a] for idx in range(len(self.data))])\n",
    "\n",
    "                # TODO collect training records for each split \n",
    "                # `splits[val]` holds a list of records for a given split,\n",
    "                # where `val` is an element of `split_cond`\n",
    "                for val in split_cond:\n",
    "                    splits[val] = records\n",
    "                \n",
    "            elif ATTR[a].type == AttrType.num:  # numerical attribute => binary split on median value\n",
    "                split_mode = SplitType.bin\n",
    "                split_cond = self.__median(a)  # (i.e., if less or equal than this value)\n",
    "                \n",
    "                # TODO collect training records for each split (in `splits`)\n",
    "                splits[split_cond] = records\n",
    "            \n",
    "            # TODO compute gain for attribute a\n",
    "            infogain = 0\n",
    "            # p = len(y_true) / len(y)\n",
    "            # entropy = calculate_entropy(y)\n",
    "            # info_gain = entropy - p*calculate_entropy(y_true) - (1-p)*calculate_entropy(y_false)\n",
    "            splitting = Splitting(a, infogain, split_mode, split_cond, splits)\n",
    "            splittings.append(splitting)\n",
    "\n",
    "        # find best splitting\n",
    "        best_splitting = sorted(splittings, key=lambda x: x.infogain, reverse=True)[0]\n",
    "        return best_splitting\n",
    "\n",
    "    def __add_node(self, parent_id, node_type=NodeType.internal, edge_value=None, val=None, split_type=None,\n",
    "                   split_cond=None):\n",
    "        \"\"\"\n",
    "        Adds a node to the decision tree.\n",
    "\n",
    "        :param parent_id:\n",
    "        :param node_type:\n",
    "        :param edge_value:\n",
    "        :param val:\n",
    "        :param split_type:\n",
    "        :param split_cond:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        node_id = len(self.model)  # id of the newly assigned node\n",
    "        if not self.model:  # the tree is empty\n",
    "            node_type = NodeType.root\n",
    "\n",
    "        node = Node(node_id, node_type, parent_id, children=[], edge_value=edge_value, val=val, split_type=split_type,\n",
    "                    split_cond=split_cond)\n",
    "        self.model.append(node)\n",
    "\n",
    "        # also add it as a child of the parent node\n",
    "        if parent_id is not None:\n",
    "            self.model[parent_id].append_child(node_id)\n",
    "\n",
    "        return node_id\n",
    "\n",
    "    def __id3(self, attrs, records, parent_id=None, value=None):\n",
    "        \"\"\"\n",
    "        Function ID3 that returns a decision tree.\n",
    "\n",
    "        :param attrs: Set of attributes\n",
    "        :param records: Training set (list of record ids)\n",
    "        :param parent_id: ID of parent node\n",
    "        :param value: Value corresponding to the parent attribute, i.e., label of the edge on which we arrived to this node\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # empty training set or empty set of attributes => create leaf node with default class\n",
    "        if not records or not attrs:\n",
    "            self.__add_node(parent_id, node_type=NodeType.leaf, edge_value=value, val=self.default_class)\n",
    "            return\n",
    "\n",
    "        # if all records have the same target value => create leaf node with that target value\n",
    "        same = all(self.data[idx][IDX_TARGET] == self.data[records[0]][IDX_TARGET] for idx in records)\n",
    "        if same:\n",
    "            target = self.data[records[0]][IDX_TARGET]\n",
    "            self.__add_node(parent_id, node_type=NodeType.leaf, edge_value=value, val=target)\n",
    "            return\n",
    "\n",
    "        # find the attribute with the largest gain\n",
    "        splitting = self.__find_best_attr(attrs, records)\n",
    "        # add node\n",
    "        node_id = self.__add_node(parent_id, edge_value=value, val=splitting.attr, split_type=splitting.split_type,\n",
    "                                  split_cond=splitting.cond)\n",
    "        # TODO call tree construction recursively for each split\n",
    "\n",
    "    def print_model(self, node_id=0, level=0):\n",
    "        node = self.model[node_id]\n",
    "        indent = \"  \" * level\n",
    "        if node.type == NodeType.leaf:\n",
    "            print(indent + str(node.edge_value) + \" [Leaf node] class=\" + node.val)\n",
    "        else:\n",
    "            cond = \" <= \" + str(node.split_cond) if ATTR[node.val].type == AttrType.num else \" == ? \"\n",
    "            if node.type == NodeType.root:\n",
    "                print(\"[Root node] '\" + ATTR[node.val].label + \"'\" + cond)\n",
    "            else:\n",
    "                print(indent + str(node.edge_value) + \" [Internal node] '\" + ATTR[node.val].label + \"'\" + cond)\n",
    "            # print tree for child notes recursively\n",
    "            for n_id in node.children:\n",
    "                self.print_model(n_id, level + 1)\n",
    "\n",
    "    def build_model(self):\n",
    "        self.__load_data()\n",
    "        self.model = []  # holds the decision tree model, represented as a list of nodes\n",
    "        # Get majority class\n",
    "        #   Note: Counter returns a dictionary, most_common(x) returns a list with the x most common elements as\n",
    "        #         (key, count) tuples; we need to take the first element of the list and the first element of the tuple\n",
    "        # self.default_target = mean([x[IDX_TARGET] for x in self.data])\n",
    "        target_list = []\n",
    "        for x in self.data:\n",
    "            target_list.append(x[IDX_TARGET])\n",
    "        # self.default_target = [int(n) for n in target_list] TRENGER VI DEN??\n",
    "        self.__id3(set(range(len(ATTR) - 1)), list(range(len(self.data))))\n",
    "\n",
    "    def apply_model(self, record):\n",
    "        node = self.model[0]\n",
    "        while node.type != NodeType.leaf:\n",
    "        # TODO based on the value of the record's attribute that is tested in `node`,# set `node` to one of its child nodes until a leaf node is reached\n",
    "         return node.val\n",
    "         \n",
    "    def predict(self, records):\n",
    "        predictions = []\n",
    "        for record in records:\n",
    "            pred_val = self.apply_model(self, record)\n",
    "            # TODO append pred_val to predictions\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c3af5e",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "   \n",
    "A class RF representing the random forest classifier. It could represent with methods:\n",
    "\n",
    "subsampling from the dataset\n",
    "build a model with multiple decision trees\n",
    "apply the model\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "10989065",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RF(object):\n",
    "    def __init__(self):\n",
    "        self.data = None  # training data set (loaded into memory)\n",
    "        self.trees = None  # decision trees\n",
    "    \n",
    "    def __load_data(self):\n",
    "        pass\n",
    "        \n",
    "    def __subsampling(self, train_set, sample_size_ratio):\n",
    "        sample_number = round(len(self.data) * sample_size_ratio)\n",
    "        # TODO: generate a subsample with replacement\n",
    "    def build_model(self, train_set, split_conditions, sample_size_ratio, number_of_trees):\n",
    "        for i in range(number_of_trees):\n",
    "            sample = self.__subsampling(train_set, sample_size_ratio)\n",
    "            tree = DT() # build a tree with sample data and split conditions\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    def predict(self, test_set):\n",
    "        rf_predictions = []\n",
    "        for row in test_set:\n",
    "            predictions = [tree.predict(row) for tree in self.trees]\n",
    "            rf_predictions.append(np.mean(predictions))\n",
    "        return rf_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "94e5fc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    dt = DT()\n",
    "    dt.build_model()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
