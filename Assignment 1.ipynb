{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0163b57",
   "metadata": {},
   "source": [
    "Assignment 1 - Building a Random Forest\n",
    "This is a skeleton of a Random Forest classifier.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "b9c04941",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import math\n",
    "from statistics import median, mode, mean\n",
    "from collections import Counter\n",
    "from enum import Enum\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statistics\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f599844",
   "metadata": {},
   "source": [
    "Some simple type definitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "41d87eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttrType(Enum):\n",
    "    cat = 0  # categorical (qualitative) attribute\n",
    "    num = 1  # numerical (quantitative) attribute\n",
    "    target = 2  # target label\n",
    "\n",
    "class NodeType(Enum):\n",
    "    root = 0\n",
    "    internal = 1\n",
    "    leaf = 2\n",
    "\n",
    "class SplitType(Enum):\n",
    "    bin = 0  # binary split\n",
    "    multi = 1  # multi-way split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6b985b",
   "metadata": {},
   "source": [
    "Also, some basic classes to represent an attribute, a spltting procedure, and a node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "4ff84975",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attribute(object):\n",
    "    def __init__(self, label, type):\n",
    "        assert type in AttrType\n",
    "        self.label = label\n",
    "        self.type = type\n",
    "        self.stat = None  # holds mean for numerical and mode for categorical attributes\n",
    "\n",
    "\n",
    "class Splitting(object):\n",
    "    def __init__(self, attr, infogain, split_type, cond, splits):\n",
    "        self.attr = attr  # attribute ID (index in ATTR)\n",
    "        self.infogain = infogain  # information gain if splitting is done on this attribute\n",
    "        self.split_type = split_type  # one of SplitType\n",
    "        self.cond = cond  # splitting condition, i.e., values on outgoing edges\n",
    "        self.splits = splits  # list of training records (IDs) for each slitting condition\n",
    "\n",
    "\n",
    "class Node(object):\n",
    "    def __init__(self, id, type, parent_id, children=None, edge_value=None, val=None, split_type=None, split_cond=None,\n",
    "                 infogain=None):\n",
    "        self.id = id  # ID (same as the index in DT.model list)\n",
    "        self.type = type  # one of NodeType\n",
    "        self.parent_id = parent_id  # ID of parent node (None if root)\n",
    "        self.children = children  # list of IDs of child nodes\n",
    "        self.edge_value = edge_value  # the value of the incoming edge (only if not root node)\n",
    "        self.val = val  # if root or internal node: the attribute that is compared at that node; if leaf node: the target value\n",
    "        self.split_type = split_type  # one of SplitType\n",
    "        self.split_cond = split_cond  # splitting condition (median value for binary splits on numerical values; otherwise a list of categorical values (corresponding to child nodes))\n",
    "        self.infogain = infogain\n",
    "\n",
    "    def append_child(self, node_id):\n",
    "        self.children.append(node_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "fd5166b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('housing_price_train.csv')\n",
    "df['LotFrontage'] = df['LotFrontage'].fillna(df['LotFrontage'].median())\n",
    "df.set_index('Id')\n",
    "df.to_csv('housing_price_train1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "b111ac50",
   "metadata": {},
   "outputs": [],
   "source": [
    "ATTR = []\n",
    "INFILE = \"housing_price_train1.csv\"\n",
    "\n",
    "for col in df.columns:\n",
    "    if col == \"SalePrice\":\n",
    "        ATTR.append(Attribute(col, AttrType.target))\n",
    "    elif col == \"MSSubClass\" or col == \"OverallQual\" or col == \"OverallCond\":\n",
    "        ATTR.append(Attribute(col, AttrType.cat))\n",
    "    elif df[col].unique().dtype == \"int64\" or df[col].unique().dtype == \"float64\":\n",
    "        ATTR.append(Attribute(col, AttrType.num))        \n",
    "    else:\n",
    "        ATTR.append(Attribute(col, AttrType.cat))\n",
    "\n",
    "IDX_TARGET = len(ATTR) - 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "a6dfb1dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning_Cat</th>\n",
       "      <th>LotFrontage_Cat</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street_Cat</th>\n",
       "      <th>Alley_Cat</th>\n",
       "      <th>LotShape_Cat</th>\n",
       "      <th>LandContour_Cat</th>\n",
       "      <th>Utilities_Cat</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC_Cat</th>\n",
       "      <th>Fence_Cat</th>\n",
       "      <th>MiscFeature_Cat</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType_Cat</th>\n",
       "      <th>SaleCondition_Cat</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>36</td>\n",
       "      <td>8450</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>51</td>\n",
       "      <td>9600</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>11250</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>9550</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>55</td>\n",
       "      <td>14260</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>1456</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>7917</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>1457</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>56</td>\n",
       "      <td>13175</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>1458</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>37</td>\n",
       "      <td>9042</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2500</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>266500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>1459</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>9717</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>142125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>1460</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>46</td>\n",
       "      <td>9937</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>147500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id  MSSubClass  MSZoning_Cat  LotFrontage_Cat  LotArea  Street_Cat  \\\n",
       "0        1          60             3               36     8450           1   \n",
       "1        2          20             3               51     9600           1   \n",
       "2        3          60             3               39    11250           1   \n",
       "3        4          70             3               31     9550           1   \n",
       "4        5          60             3               55    14260           1   \n",
       "...    ...         ...           ...              ...      ...         ...   \n",
       "1455  1456          60             3               33     7917           1   \n",
       "1456  1457          20             3               56    13175           1   \n",
       "1457  1458          70             3               37     9042           1   \n",
       "1458  1459          20             3               39     9717           1   \n",
       "1459  1460          20             3               46     9937           1   \n",
       "\n",
       "      Alley_Cat  LotShape_Cat  LandContour_Cat  Utilities_Cat  ...  PoolArea  \\\n",
       "0            -1             3                3              0  ...         0   \n",
       "1            -1             3                3              0  ...         0   \n",
       "2            -1             0                3              0  ...         0   \n",
       "3            -1             0                3              0  ...         0   \n",
       "4            -1             0                3              0  ...         0   \n",
       "...         ...           ...              ...            ...  ...       ...   \n",
       "1455         -1             3                3              0  ...         0   \n",
       "1456         -1             3                3              0  ...         0   \n",
       "1457         -1             3                3              0  ...         0   \n",
       "1458         -1             3                3              0  ...         0   \n",
       "1459         -1             3                3              0  ...         0   \n",
       "\n",
       "      PoolQC_Cat  Fence_Cat  MiscFeature_Cat  MiscVal  MoSold  YrSold  \\\n",
       "0             -1         -1               -1        0       2    2008   \n",
       "1             -1         -1               -1        0       5    2007   \n",
       "2             -1         -1               -1        0       9    2008   \n",
       "3             -1         -1               -1        0       2    2006   \n",
       "4             -1         -1               -1        0      12    2008   \n",
       "...          ...        ...              ...      ...     ...     ...   \n",
       "1455          -1         -1               -1        0       8    2007   \n",
       "1456          -1          2               -1        0       2    2010   \n",
       "1457          -1          0                2     2500       5    2010   \n",
       "1458          -1         -1               -1        0       4    2010   \n",
       "1459          -1         -1               -1        0       6    2008   \n",
       "\n",
       "      SaleType_Cat  SaleCondition_Cat  SalePrice  \n",
       "0                8                  4     208500  \n",
       "1                8                  4     181500  \n",
       "2                8                  4     223500  \n",
       "3                8                  0     140000  \n",
       "4                8                  4     250000  \n",
       "...            ...                ...        ...  \n",
       "1455             8                  4     175000  \n",
       "1456             8                  4     210000  \n",
       "1457             8                  4     266500  \n",
       "1458             8                  4     142125  \n",
       "1459             8                  4     147500  \n",
       "\n",
       "[1460 rows x 81 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Could make a new df with only colums with numerical values and categories\n",
    "numerical_df = pd.DataFrame()\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == \"int64\":\n",
    "        numerical_df[col] = df[col]\n",
    "        continue\n",
    "    else:\n",
    "        df[col] = df[col].astype(\"category\")\n",
    "        new_col = '{val}_Cat'.format(val=col)\n",
    "        numerical_df[new_col] = df[col].cat.codes\n",
    "        \n",
    "        # df[col] = df[col].astype(\"category\")\n",
    "        # new_col = '{val}_Cat'.format(val=col)\n",
    "        # df[new_col] = df[col].cat.codes\n",
    "numerical_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d4b0a0",
   "metadata": {},
   "source": [
    "A class DT representing the decision tree classifier. It could represent with methods:\n",
    "\n",
    "a given impurity measure;\n",
    "the search for the best attribute to split with;\n",
    "the addition of a node to the tree;\n",
    "a convenient model printer;\n",
    "the recursive call for obtaining a tree;\n",
    "a builder and an applier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "a5d23f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DT(object):\n",
    "    def __init__(self):\n",
    "        self.data = None  # training data set (loaded into memory)\n",
    "        self.model = None  # decision tree model\n",
    "        # self.default_target = 0.0  # default target class HVA ER DET FOR NOE?\n",
    "\n",
    "    def __load_data(self):\n",
    "        # with open(INFILE) as csvfile:\n",
    "        #     self.data = []\n",
    "        #     csvreader = csv.reader(csvfile, delimiter=',')\n",
    "        #     next(csvreader)\n",
    "        #     for row in csvreader:\n",
    "        #         rec = []\n",
    "        #         for i in range(len(ATTR)):\n",
    "        #             val = row[i].strip()\n",
    "        #             # convert numerical attributes\n",
    "        #             if ATTR[i].type == AttrType.num:  # Note that this will break for \"?\" (missing attribute)\n",
    "        #                 if val == \"\":\n",
    "        #                     val = None\n",
    "        #                 else:\n",
    "        #                     val = float(val)\n",
    "        #             rec.append(val)\n",
    "        #         self.data.append(rec)\n",
    "        #     # print(self.data)\n",
    "        #         # self.data.append([element.strip() for element in row])  # strip spaces\n",
    "        self.data = numerical_df.values.tolist()\n",
    "                \n",
    "    def __median(self, a):\n",
    "        all_attribute_values = []\n",
    "        for idx in range(len(self.data)):\n",
    "            all_attribute_values.append(self.data[idx][a])\n",
    "        return statistics.median(all_attribute_values)\n",
    "    \n",
    "    \n",
    "    def __split_cat(self, a, split_cond):\n",
    "        \"\"\"\n",
    "        :return: returns the id of splitted values\n",
    "        \"\"\"\n",
    "        children = []\n",
    "        for val in split_cond:\n",
    "            child = []\n",
    "            for idx in range(len(self.data)):\n",
    "                if self.data[idx][a] == val:\n",
    "                    child.append(idx)\n",
    "            if len(child) != 0:\n",
    "                children.append(child)\n",
    "        return children\n",
    "\n",
    "    def __split_num(self, a, splitting_point):\n",
    "        \"\"\"\n",
    "        :return: returns the id of splitted values \n",
    "        \"\"\"\n",
    "        children = [[x[0] for x in self.data if x[a] <= splitting_point],\n",
    "                    [x[0] for x in self.data if x[a] > splitting_point]]\n",
    "        return children\n",
    "       \n",
    "\n",
    "        \n",
    "    def __find_best_attr(self, attrs, records):\n",
    "        \"\"\"\n",
    "        Finds the attribute with the largest gain.\n",
    "\n",
    "        :param attrs: Set of attributes\n",
    "        :param records: Training set (list of record ids)\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # mse_p = self.__mean_squared_error(records)  # parent's MSE HVORFOR TRENGER VI DEN?\n",
    "        splittings = []  # holds the splitting information for each attribute\n",
    "\n",
    "        for a in attrs:\n",
    "            assert ATTR[a].type in AttrType\n",
    "            splits = {}  # record IDs corresponding to each split\n",
    "            # splitting condition depends on the attribute type\n",
    "            if ATTR[a].type == AttrType.target:  # skip target attribute\n",
    "                continue\n",
    "            elif ATTR[a].type == AttrType.cat:  # categorical attribute\n",
    "                # multi-way split on each possible value\n",
    "                split_mode = SplitType.multi\n",
    "                # each possible attr value corresponds to a split (indexed with categorical labels)\n",
    "                # Note: it's important to consider attr values from the entire training set\n",
    "                split_cond = set([self.data[idx][a] for idx in range(len(self.data))])\n",
    "\n",
    "                # TODO collect training records for each split \n",
    "                # `splits[val]` holds a list of records for a given split,\n",
    "                # where `val` is an element of `split_cond`\n",
    "                children = self.__split_cat(a, split_cond)\n",
    "                for i, val in enumerate(split_cond):\n",
    "                    splits[val] = children[i]\n",
    "                \n",
    "            elif ATTR[a].type == AttrType.num:  # numerical attribute => binary split on median value\n",
    "                split_mode = SplitType.bin\n",
    "                split_cond = self.__median(a)  # (i.e., if less or equal than this value)\n",
    "                split_cond_list = []\n",
    "                split_cond_list.append(\"{}.1\".format(split_cond))\n",
    "                split_cond_list.append(\"{}.2\".format(split_cond))\n",
    "                \n",
    "                # TODO collect training records for each split (in `splits`)\n",
    "                children = self.__split_num(a, split_cond)\n",
    "                for i, val in enumerate(split_cond_list):\n",
    "                    splits[val] = children[i]\n",
    "            \n",
    "            # TODO compute gain for attribute a\n",
    "            #print(splits)\n",
    "            \n",
    "            infogain = 0\n",
    "            datalist = []\n",
    "            target = []\n",
    "            for idx in range(len(self.data)):\n",
    "                datalist.append(self.data[idx][a])\n",
    "                target.append(self.data[idx][-1])\n",
    "            target_df = pd.DataFrame(target, columns=[\"SalePrice\"])\n",
    "            datalist_df = pd.DataFrame(datalist)\n",
    "            #data_df = pd.DataFrame(self.data)\n",
    "            \n",
    "            data_split = self.__split(df, datalist_df[0])\n",
    "            split_labels = [dataframe['SalePrice'] for dataframe in data_split]\n",
    "            infogain = self.__calculate_information_gain(target_df, split_labels)\n",
    "            \n",
    "            # p = len(y_true) / len(y)\n",
    "            # entropy = calculate_entropy(y)\n",
    "            # info_gain = entropy - p*calculate_entropy(y_true) - (1-p)*calculate_entropy(y_false)\n",
    "            splitting = Splitting(a, infogain, split_mode, split_cond, splits)\n",
    "            splittings.append(splitting)\n",
    "\n",
    "        # find best splitting\n",
    "        best_splitting = sorted(splittings, key=lambda x: x.infogain, reverse=True)[0]\n",
    "        return best_splitting\n",
    "    \n",
    "#########################################################################################\n",
    "########################## Funksjoner til å kalkulere infogain ##########################    \n",
    "#########################################################################################    \n",
    "    def __calculate_entropy(self, labels):\n",
    "        n_labels = len(labels)\n",
    "        if n_labels <= 1:\n",
    "            return 0\n",
    "        value, counts = np.unique(labels, return_counts=True)\n",
    "        probs = counts/n_labels\n",
    "        n_classes = len(value)\n",
    "        if n_classes <= 1:\n",
    "            return 0\n",
    "        entropy = 0\n",
    "        for i in probs:\n",
    "            entropy -= i*log(i,2)\n",
    "        return entropy\n",
    "    def __calculate_information_gain(self, target, split):\n",
    "        info_gain = self.__calculate_entropy(target)\n",
    "        for branch in split:\n",
    "            p = len(branch)/len(target)\n",
    "            info_gain -= p*self.__calculate_entropy(branch)\n",
    "        return info_gain\n",
    "    \n",
    "    def __split(self, dataset, datalist):\n",
    "        split_data = []\n",
    "        col_vals = datalist.unique()\n",
    "        for col_val in col_vals:\n",
    "            split_data.append(dataset[datalist == col_val])\n",
    "        return(split_data)\n",
    "#########################################################################################\n",
    "#########################################################################################\n",
    "\n",
    "    def __add_node(self, parent_id, node_type=NodeType.internal, edge_value=None, val=None, split_type=None,\n",
    "                   split_cond=None):\n",
    "        \"\"\"\n",
    "        Adds a node to the decision tree.\n",
    "\n",
    "        :param parent_id:\n",
    "        :param node_type:\n",
    "        :param edge_value:\n",
    "        :param val:\n",
    "        :param split_type:\n",
    "        :param split_cond:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        node_id = len(self.model)  # id of the newly assigned node\n",
    "        if not self.model:  # the tree is empty\n",
    "            node_type = NodeType.root\n",
    "\n",
    "        node = Node(node_id, node_type, parent_id, children=[], edge_value=edge_value, val=val, split_type=split_type,\n",
    "                    split_cond=split_cond)\n",
    "        self.model.append(node)\n",
    "\n",
    "        # also add it as a child of the parent node\n",
    "        if parent_id is not None:\n",
    "            self.model[parent_id].append_child(node_id)\n",
    "\n",
    "        return node_id\n",
    "\n",
    "    def __id3(self, attrs, records, parent_id=None, value=None):\n",
    "        \"\"\"\n",
    "        Function ID3 that returns a decision tree.\n",
    "\n",
    "        :param attrs: Set of attributes\n",
    "        :param records: Training set (list of record ids)\n",
    "        :param parent_id: ID of parent node\n",
    "        :param value: Value corresponding to the parent attribute, i.e., label of the edge on which we arrived to this node\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # empty training set or empty set of attributes => create leaf node with default class\n",
    "        if not records or not attrs:\n",
    "            self.__add_node(parent_id, node_type=NodeType.leaf, edge_value=value, val=self.default_class)\n",
    "            return\n",
    "\n",
    "        # if all records have the same target value => create leaf node with that target value\n",
    "        same = all(self.data[idx][IDX_TARGET] == self.data[records[0]][IDX_TARGET] for idx in records)\n",
    "        if same:\n",
    "            target = self.data[records[0]][IDX_TARGET]\n",
    "            self.__add_node(parent_id, node_type=NodeType.leaf, edge_value=value, val=target)\n",
    "            return\n",
    "\n",
    "        # find the attribute with the largest gain\n",
    "        splitting = self.__find_best_attr(attrs, records)\n",
    "        # add node\n",
    "        node_id = self.__add_node(parent_id, edge_value=value, val=splitting.attr, split_type=splitting.split_type,\n",
    "                                  split_cond=splitting.cond)\n",
    "        # TODO call tree construction recursively for each split\n",
    "        node = self.model[node_id]\n",
    "        for n in node.children:\n",
    "            self.__id3(attrs, records, node_id, node.val)\n",
    "        return self.model\n",
    "\n",
    "\n",
    "    def print_model(self, node_id=0, level=0):\n",
    "        node = self.model[node_id]\n",
    "        indent = \"  \" * level\n",
    "        if node.type == NodeType.leaf:\n",
    "            print(indent + str(node.edge_value) + \" [Leaf node] class=\" + node.val)\n",
    "        else:\n",
    "            cond = \" <= \" + str(node.split_cond) if ATTR[node.val].type == AttrType.num else \" == ? \"\n",
    "            if node.type == NodeType.root:\n",
    "                print(\"[Root node] '\" + ATTR[node.val].label + \"'\" + cond)\n",
    "            else:\n",
    "                print(indent + str(node.edge_value) + \" [Internal node] '\" + ATTR[node.val].label + \"'\" + cond)\n",
    "            # print tree for child notes recursively\n",
    "            for n_id in node.children:\n",
    "                self.print_model(n_id, level + 1)\n",
    "\n",
    "    def build_model(self):\n",
    "        self.__load_data()\n",
    "        self.model = []  # holds the decision tree model, represented as a list of nodes\n",
    "        # Get majority class\n",
    "        #   Note: Counter returns a dictionary, most_common(x) returns a list with the x most common elements as\n",
    "        #         (key, count) tuples; we need to take the first element of the list and the first element of the tuple\n",
    "        # self.default_target = mean([x[IDX_TARGET] for x in self.data])\n",
    "        target_list = []\n",
    "        for x in self.data:\n",
    "            target_list.append(x[IDX_TARGET])\n",
    "        # self.default_target = [int(n) for n in target_list] TRENGER VI DEN??\n",
    "        self.__id3(set(range(len(ATTR) - 1)), list(range(len(self.data))))\n",
    "\n",
    "    def apply_model(self, record):\n",
    "        node = self.model[0]\n",
    "        while node.type != NodeType.leaf:\n",
    "        # TODO based on the value of the record's attribute that is tested in `node`,\n",
    "        # set `node` to one of its child nodes until a leaf node is reached\n",
    "            #print(node)\n",
    "            continue\n",
    "        return node.val\n",
    "         \n",
    "    def predict(self, records):\n",
    "        predictions = []\n",
    "        for record in records:\n",
    "            print(record)\n",
    "            pred_val = self.apply_model(record)\n",
    "            # TODO append pred_val to predictions\n",
    "            predictions.append(pred_val)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "dcf82f1d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11876/1000060090.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDT\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m#dt.print_model()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11876/838289632.py\u001b[0m in \u001b[0;36mbuild_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    253\u001b[0m             \u001b[0mtarget_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mIDX_TARGET\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;31m# self.default_target = [int(n) for n in target_list] TRENGER VI DEN??\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 255\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__id3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mATTR\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecord\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11876/838289632.py\u001b[0m in \u001b[0;36m__id3\u001b[1;34m(self, attrs, records, parent_id, value)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m         \u001b[1;31m# find the attribute with the largest gain\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 218\u001b[1;33m         \u001b[0msplitting\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__find_best_attr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    219\u001b[0m         \u001b[1;31m# add node\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m         node_id = self.__add_node(parent_id, edge_value=value, val=splitting.attr, split_type=splitting.split_type,\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11876/838289632.py\u001b[0m in \u001b[0;36m__find_best_attr\u001b[1;34m(self, attrs, records)\u001b[0m\n\u001b[0;32m    120\u001b[0m             \u001b[1;31m#data_df = pd.DataFrame(self.data)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 122\u001b[1;33m             \u001b[0mdata_split\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatalist_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    123\u001b[0m             \u001b[0msplit_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SalePrice'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdataframe\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_split\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m             \u001b[0minfogain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__calculate_information_gain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11876/838289632.py\u001b[0m in \u001b[0;36m__split\u001b[1;34m(self, dataset, datalist)\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[0mcol_vals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatalist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcol_val\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcol_vals\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m             \u001b[0msplit_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdatalist\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mcol_val\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m         \u001b[1;32mreturn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msplit_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[1;31m#########################################################################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3013\u001b[0m         \u001b[1;31m# Do we have a (boolean) 1d indexer?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3014\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_bool_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3015\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_bool_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3016\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3017\u001b[0m         \u001b[1;31m# We are left with two options: a single key, and a collection of keys,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_bool_array\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3068\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_bool_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3069\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3070\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_take_with_is_copy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3071\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3072\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_take_with_is_copy\u001b[1;34m(self, indices, axis)\u001b[0m\n\u001b[0;32m   3597\u001b[0m         \u001b[0mSee\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdocstring\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfull\u001b[0m \u001b[0mexplanation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3598\u001b[0m         \"\"\"\n\u001b[1;32m-> 3599\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3600\u001b[0m         \u001b[1;31m# Maybe set copy if we didn't actually change the index.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3601\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mequals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mtake\u001b[1;34m(self, indices, axis, is_copy, **kwargs)\u001b[0m\n\u001b[0;32m   3583\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3585\u001b[1;33m         new_data = self._mgr.take(\n\u001b[0m\u001b[0;32m   3586\u001b[0m             \u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_block_manager_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3587\u001b[0m         )\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mtake\u001b[1;34m(self, indexer, axis, verify, convert)\u001b[0m\n\u001b[0;32m   1472\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1473\u001b[0m         \u001b[0mnew_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1474\u001b[1;33m         return self.reindex_indexer(\n\u001b[0m\u001b[0;32m   1475\u001b[0m             \u001b[0mnew_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnew_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1476\u001b[0m         )\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mreindex_indexer\u001b[1;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice)\u001b[0m\n\u001b[0;32m   1309\u001b[0m             )\n\u001b[0;32m   1310\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1311\u001b[1;33m             new_blocks = [\n\u001b[0m\u001b[0;32m   1312\u001b[0m                 blk.take_nd(\n\u001b[0;32m   1313\u001b[0m                     \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1310\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1311\u001b[0m             new_blocks = [\n\u001b[1;32m-> 1312\u001b[1;33m                 blk.take_nd(\n\u001b[0m\u001b[0;32m   1313\u001b[0m                     \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1314\u001b[0m                     \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36mtake_nd\u001b[1;34m(self, indexer, axis, new_mgr_locs, fill_value)\u001b[0m\n\u001b[0;32m   1861\u001b[0m         \u001b[1;31m# but are passed the axis depending on the calling routing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1862\u001b[0m         \u001b[1;31m# if its REALLY axis 0, then this will be a reindex and not a take\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1863\u001b[1;33m         \u001b[0mnew_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_fill\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1864\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1865\u001b[0m         \u001b[1;31m# Called from three places in managers, all of which satisfy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\arrays\\_mixins.py\u001b[0m in \u001b[0;36mtake\u001b[1;34m(self, indices, allow_fill, fill_value, axis)\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[0mfill_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_fill_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m         new_data = take(\n\u001b[0m\u001b[0;32m     72\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ndarray\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m             \u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\algorithms.py\u001b[0m in \u001b[0;36mtake\u001b[1;34m(arr, indices, axis, allow_fill, fill_value)\u001b[0m\n\u001b[0;32m   1650\u001b[0m         \u001b[1;31m# Pandas style, -1 means NA\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1651\u001b[0m         \u001b[0mvalidate_indices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1652\u001b[1;33m         result = take_1d(\n\u001b[0m\u001b[0;32m   1653\u001b[0m             \u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_fill\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1654\u001b[0m         )\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\algorithms.py\u001b[0m in \u001b[0;36mtake_nd\u001b[1;34m(arr, indexer, axis, out, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m   1757\u001b[0m         \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask_info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1758\u001b[0m     )\n\u001b[1;32m-> 1759\u001b[1;33m     \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1760\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1761\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mflip_order\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dt = DT()\n",
    "dt.build_model()\n",
    "dt.print_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c3af5e",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "   \n",
    "A class RF representing the random forest classifier. It could represent with methods:\n",
    "\n",
    "subsampling from the dataset\n",
    "build a model with multiple decision trees\n",
    "apply the model\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "10989065",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RF(object):\n",
    "    def __init__(self):\n",
    "        self.data = None  # training data set (loaded into memory)\n",
    "        self.trees = None  # decision trees\n",
    "    \n",
    "    def __load_data(self):\n",
    "        pass\n",
    "        \n",
    "    def __subsampling(self, train_set, sample_size_ratio):\n",
    "        sample_number = round(len(self.data) * sample_size_ratio)\n",
    "        # TODO: generate a subsample with replacement\n",
    "    def build_model(self, train_set, split_conditions, sample_size_ratio, number_of_trees):\n",
    "        for i in range(number_of_trees):\n",
    "            sample = self.__subsampling(train_set, sample_size_ratio)\n",
    "            tree = DT() # build a tree with sample data and split conditions\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    def predict(self, test_set):\n",
    "        rf_predictions = []\n",
    "        for row in test_set:\n",
    "            predictions = [tree.predict(row) for tree in self.trees]\n",
    "            rf_predictions.append(np.mean(predictions))\n",
    "        return rf_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "94e5fc04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "###################\n",
      "1\n",
      "15\n",
      "15\n",
      "{160, 70, 40, 75, 45, 80, 50, 20, 85, 180, 30, 120, 90, 60, 190}\n",
      "###################\n",
      "2\n",
      "5\n",
      "5\n",
      "{0, 1, 2, 3, 4}\n",
      "2\n",
      "2\n",
      "###################\n",
      "5\n",
      "2\n",
      "2\n",
      "{0, 1}\n",
      "###################\n",
      "6\n",
      "3\n",
      "3\n",
      "{0, 1, -1}\n",
      "###################\n",
      "7\n",
      "4\n",
      "4\n",
      "{0, 1, 2, 3}\n",
      "###################\n",
      "8\n",
      "4\n",
      "4\n",
      "{0, 1, 2, 3}\n",
      "###################\n",
      "9\n",
      "2\n",
      "2\n",
      "{0, 1}\n",
      "###################\n",
      "10\n",
      "5\n",
      "5\n",
      "{0, 1, 2, 3, 4}\n",
      "###################\n",
      "11\n",
      "3\n",
      "3\n",
      "{0, 1, 2}\n",
      "###################\n",
      "12\n",
      "25\n",
      "25\n",
      "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24}\n",
      "###################\n",
      "13\n",
      "9\n",
      "9\n",
      "{0, 1, 2, 3, 4, 5, 6, 7, 8}\n",
      "###################\n",
      "14\n",
      "8\n",
      "8\n",
      "{0, 1, 2, 3, 4, 5, 6, 7}\n",
      "###################\n",
      "15\n",
      "5\n",
      "5\n",
      "{0, 1, 2, 3, 4}\n",
      "###################\n",
      "16\n",
      "8\n",
      "8\n",
      "{0, 1, 2, 3, 4, 5, 6, 7}\n",
      "###################\n",
      "17\n",
      "10\n",
      "10\n",
      "{1, 2, 3, 4, 5, 6, 7, 8, 9, 10}\n",
      "###################\n",
      "18\n",
      "9\n",
      "9\n",
      "{1, 2, 3, 4, 5, 6, 7, 8, 9}\n",
      "2\n",
      "2\n",
      "###################\n",
      "21\n",
      "6\n",
      "6\n",
      "{0, 1, 2, 3, 4, 5}\n",
      "###################\n",
      "22\n",
      "8\n",
      "8\n",
      "{0, 1, 2, 3, 4, 5, 6, 7}\n",
      "###################\n",
      "23\n",
      "15\n",
      "15\n",
      "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14}\n",
      "###################\n",
      "24\n",
      "16\n",
      "16\n",
      "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15}\n",
      "###################\n",
      "25\n",
      "5\n",
      "5\n",
      "{0, 1, 2, 3, -1}\n",
      "2\n",
      "###################\n",
      "27\n",
      "4\n",
      "4\n",
      "{0, 1, 2, 3}\n",
      "###################\n",
      "28\n",
      "5\n",
      "5\n",
      "{0, 1, 2, 3, 4}\n",
      "###################\n",
      "29\n",
      "6\n",
      "6\n",
      "{0, 1, 2, 3, 4, 5}\n",
      "###################\n",
      "30\n",
      "5\n",
      "5\n",
      "{0, 1, 2, 3, -1}\n",
      "###################\n",
      "31\n",
      "5\n",
      "5\n",
      "{0, 1, 2, 3, -1}\n",
      "###################\n",
      "32\n",
      "5\n",
      "5\n",
      "{0, 1, 2, 3, -1}\n",
      "###################\n",
      "33\n",
      "7\n",
      "7\n",
      "{0, 1, 2, 3, 4, 5, -1}\n",
      "2\n",
      "###################\n",
      "35\n",
      "7\n",
      "7\n",
      "{0, 1, 2, 3, 4, 5, -1}\n",
      "2\n",
      "2\n",
      "2\n",
      "###################\n",
      "39\n",
      "6\n",
      "6\n",
      "{0, 1, 2, 3, 4, 5}\n",
      "###################\n",
      "40\n",
      "5\n",
      "5\n",
      "{0, 1, 2, 3, 4}\n",
      "###################\n",
      "41\n",
      "2\n",
      "2\n",
      "{0, 1}\n",
      "###################\n",
      "42\n",
      "6\n",
      "6\n",
      "{0, 1, 2, 3, 4, -1}\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "###################\n",
      "53\n",
      "4\n",
      "4\n",
      "{0, 1, 2, 3}\n",
      "2\n",
      "###################\n",
      "55\n",
      "7\n",
      "7\n",
      "{0, 1, 2, 3, 4, 5, 6}\n",
      "2\n",
      "###################\n",
      "57\n",
      "6\n",
      "6\n",
      "{0, 1, 2, 3, 4, -1}\n",
      "###################\n",
      "58\n",
      "7\n",
      "7\n",
      "{0, 1, 2, 3, 4, 5, -1}\n",
      "2\n",
      "###################\n",
      "60\n",
      "4\n",
      "4\n",
      "{0, 1, 2, -1}\n",
      "2\n",
      "2\n",
      "###################\n",
      "63\n",
      "6\n",
      "6\n",
      "{0, 1, 2, 3, 4, -1}\n",
      "###################\n",
      "64\n",
      "6\n",
      "6\n",
      "{0, 1, 2, 3, 4, -1}\n",
      "###################\n",
      "65\n",
      "3\n",
      "3\n",
      "{0, 1, 2}\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "###################\n",
      "72\n",
      "4\n",
      "4\n",
      "{0, 1, 2, -1}\n",
      "###################\n",
      "73\n",
      "5\n",
      "5\n",
      "{0, 1, 2, 3, -1}\n",
      "###################\n",
      "74\n",
      "5\n",
      "5\n",
      "{0, 1, 2, 3, -1}\n",
      "2\n",
      "2\n",
      "2\n",
      "###################\n",
      "78\n",
      "9\n",
      "9\n",
      "{0, 1, 2, 3, 4, 5, 6, 7, 8}\n",
      "###################\n",
      "79\n",
      "6\n",
      "6\n",
      "{0, 1, 2, 3, 4, 5}\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    dt = DT()\n",
    "    dt.build_model()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
